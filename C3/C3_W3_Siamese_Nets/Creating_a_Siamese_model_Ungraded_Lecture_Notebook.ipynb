{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKaywkJyxj09",
        "outputId": "8ab80363-2450-4cec-9b52-972eba99634e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e2e87e84ad0>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3V2B_X_zjNY"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v6f9_ASTzwK0"
      },
      "outputs": [],
      "source": [
        "vocab_size = 500\n",
        "model_dimension = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "tNHWnrmYziGA"
      },
      "outputs": [],
      "source": [
        "class NormalizationLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return F.normalize(x, dim=1)\n",
        "\n",
        "class BaseNetwork(nn.Module):\n",
        "    def __init__(self, vocab_size, model_dimension):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, model_dimension)\n",
        "        self.lstm = nn.LSTM(model_dimension, model_dimension, batch_first=True)\n",
        "        self.pooling = nn.AvgPool1d(kernel_size=2)\n",
        "        self.l2norm = NormalizationLayer()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = torch.transpose(x, 1, 2)\n",
        "        x = self.pooling(x)\n",
        "        x = self.l2norm(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.LSTM = BaseNetwork(vocab_size, model_dimension)\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.LSTM(input1)\n",
        "        output2 = self.LSTM(input2)\n",
        "        conc = torch.cat((output1, output2), dim=1)\n",
        "\n",
        "        return conc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "e_aT4QZ7PKcL"
      },
      "outputs": [],
      "source": [
        "siamese_nn = SiameseNetwork()\n",
        "LSTM = BaseNetwork(vocab_size, model_dimension)\n",
        "\n",
        "inputs1 = torch.randint(0, vocab_size, (32, 100))\n",
        "inputs2 = torch.randint(0, vocab_size, (32, 100))\n",
        "\n",
        "outputs = siamese_nn(inputs1, inputs2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK3x8E_McJqb",
        "outputId": "4b9f9d71-d822-42bd-eb7a-a357e8cb132d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Siamese model:\n",
            "Model: SiameseNetwork\n",
            "==================================================\n",
            "SiameseNetwork.LSTM: BaseNetwork\n",
            "SiameseNetwork.  embedding: Embedding\n",
            "SiameseNetwork.  lstm: LSTM\n",
            "SiameseNetwork.  pooling: AvgPool1d\n",
            "SiameseNetwork.  l2norm: NormalizationLayer\n",
            "\n",
            "Total parameters: 196096\n",
            "\n",
            "Detail of Base Network:\n",
            "Model: BaseNetwork\n",
            "==================================================\n",
            "BaseNetwork.embedding: Embedding\n",
            "BaseNetwork.lstm: LSTM\n",
            "BaseNetwork.pooling: AvgPool1d\n",
            "BaseNetwork.l2norm: NormalizationLayer\n",
            "\n",
            "Total parameters: 196096\n"
          ]
        }
      ],
      "source": [
        "def show_layers(model, layer_prefix=''):\n",
        "    def recurse(module, prefix=''):\n",
        "        for name, child in module.named_children():\n",
        "            class_name = child.__class__.__name__\n",
        "            print(f'{prefix}{name}: {class_name}')\n",
        "            if list(child.children()):  # if the child has children, recurse\n",
        "                recurse(child, prefix + '  ')\n",
        "\n",
        "    print(f\"Model: {model.__class__.__name__}\")\n",
        "    print(\"=\" * 50)\n",
        "    recurse(model, layer_prefix)\n",
        "    print(\"\\nTotal parameters:\", sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "# Usage:\n",
        "print('Siamese model:')\n",
        "show_layers(siamese_nn, 'SiameseNetwork.')\n",
        "\n",
        "print('\\nDetail of Base Network:')\n",
        "show_layers(LSTM, 'BaseNetwork.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Jn0PlXYMgdQ2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

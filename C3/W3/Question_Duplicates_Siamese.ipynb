{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data import & preparation"
      ],
      "metadata": {
        "id": "YP3VQobk-iSE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i3nYWgup7oXV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rnd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yIev8rha9OnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25092b97-b5da-4b42-9194-542bc8c1b91c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/SequenceModelsCoursera/W3_Siamese/Question Duplicates /Files/tf"
      ],
      "metadata": {
        "id": "Fm97QTiA9tpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af8c24a-dc05-4f7d-b763-c8f2cc31e984"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SequenceModelsCoursera/W3_Siamese/Question Duplicates /Files/tf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"questions.csv\")\n",
        "N = len(data)\n",
        "\n",
        "print(f\"Num of question pairs: {N}\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "RjhxsSCB9xdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "f0271146-477b-4575-e7d3-63d228ea5d09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of question pairs: 404351\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43c363b4-204a-429b-8e15-12067cdd73a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43c363b4-204a-429b-8e15-12067cdd73a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43c363b4-204a-429b-8e15-12067cdd73a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43c363b4-204a-429b-8e15-12067cdd73a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a6a94d9-115a-4a4e-80bc-0e620d8ea1b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a6a94d9-115a-4a4e-80bc-0e620d8ea1b1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a6a94d9-115a-4a4e-80bc-0e620d8ea1b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_train = 300000\n",
        "N_test = 10240\n",
        "data_train = data[:N_train]\n",
        "data_test = data[N_train:N_train + N_test]\n",
        "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n",
        "del (data)  # remove to free memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81NZo_iK-dM0",
        "outputId": "842c200f-8603-4924-e5d2-04afb34c3cf1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 300000 Test set: 10240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Row indices of entries where the duplicate is true\n",
        "td_index = data_train['is_duplicate'] == 1\n",
        "td_index = [i for i, x in enumerate(td_index) if x ]\n",
        "print(f\"Number of duplicates: {len(td_index)}\")\n",
        "print(f\"Indices of the first ten duplicates: {td_index[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D187Di9chCLh",
        "outputId": "26a4b331-46fa-4a0a-971f-de52ef753635"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 111486\n",
            "Indices of the first ten duplicates: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_train['question1'][5])\n",
        "print(data_train['question2'][5])\n",
        "print('is_duplicate: ', data_train['is_duplicate'][5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoZBVlHxhfBF",
        "outputId": "6277a0f7-f166-4113-c6d1-f62d6bd2bdb6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
            "is_duplicate:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retreiving only the duplicate data because the hard negative mining will account for negative examples for the model to train\n",
        "Q1_train = np.array(data_train['question1'][td_index])\n",
        "Q2_train = np.array(data_train['question2'][td_index])\n",
        "\n",
        "Q1_test = np.array(data_test['question1'])\n",
        "Q2_test = np.array(data_test['question2'])\n",
        "y_test = np.array(data_test['is_duplicate'])"
      ],
      "metadata": {
        "id": "sld1T5dWiEgu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3kQ5fNVn_Hs",
        "outputId": "47830046-1f6b-49d9-ce94-8972ff9434d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10240,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('TRAINING QUESTIONS:\\n')\n",
        "print('Question 1: ', Q1_train[0])\n",
        "print('Question 2: ', Q2_train[0], '\\n')\n",
        "print('Question 1: ', Q1_train[5])\n",
        "print('Question 2: ', Q2_train[5], '\\n')\n",
        "\n",
        "print('TESTING QUESTIONS:\\n')\n",
        "print('Question 1: ', Q1_test[0])\n",
        "print('Question 2: ', Q2_test[0], '\\n')\n",
        "print('is_duplicate =', y_test[0], '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIvXUOCzoB_r",
        "outputId": "8dc51388-40f1-4bec-b7b1-ed7bfe980c7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING QUESTIONS:\n",
            "\n",
            "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
            "\n",
            "Question 1:  What would a Trump presidency mean for current international masterâ€™s students on an F1 visa?\n",
            "Question 2:  How will a Trump presidency affect the students presently in US or planning to study in US? \n",
            "\n",
            "TESTING QUESTIONS:\n",
            "\n",
            "Question 1:  How do I prepare for interviews for cse?\n",
            "Question 2:  What is the best way to prepare for cse? \n",
            "\n",
            "is_duplicate = 0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data for train & val set respectively\n",
        "cut_off = int(len(Q1_train) * 0.8)\n",
        "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
        "val_Q1, val_Q2 = Q1_train[cut_off:], Q2_train[cut_off:]\n",
        "print(f\"Number of duplicate questions: {len(Q1_train)}\")\n",
        "print(f\"The length of the training set: {len(train_Q1)}\")\n",
        "print(f\"The length of the validation set: {len(val_Q1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHvTzunIoMRo",
        "outputId": "6917ec0c-20ed-44cb-caef-58392aa98169"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate questions: 111486\n",
            "The length of the training set: 89188\n",
            "The length of the validation set: 22298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding text & padding"
      ],
      "metadata": {
        "id": "4AoXWv2Spp4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Punctuation stripping"
      ],
      "metadata": {
        "id": "fSWsE5r5RQsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def strip_punctuation(text):\n",
        "    stripped_sequences = []\n",
        "\n",
        "    #Converting a single string to a list if it was passed\n",
        "    if isinstance(text, str):\n",
        "        text = [text]\n",
        "\n",
        "    #Stripping punctuation\n",
        "    for sequence in text:\n",
        "        stripped_sequences.append(''.join(char for char in sequence if char not in string.punctuation))\n",
        "\n",
        "    return stripped_sequences"
      ],
      "metadata": {
        "id": "wG391Wm5smSj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\"Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\", \"I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\"]\n",
        "print(f\"Before stripping: {samples}\")\n",
        "print(f\"Post stripping: {strip_punctuation(samples)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELcGZYCiF3q3",
        "outputId": "dda854fb-6f0c-4ae3-a4b5-d09b5b78974f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before stripping: ['Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?', \"I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\"]\n",
            "Post stripping: ['Astrology I am a Capricorn Sun Cap moon and cap risingwhat does that say about me', 'Im a triple Capricorn Sun Moon and ascendant in Capricorn What does this say about me']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\"\n",
        "print(f\"Before stripping: {samples}\")\n",
        "print(f\"Post stripping: {strip_punctuation(sample)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhviGRZsQzHg",
        "outputId": "b5459258-d6d8-4bf2-9ef3-2ff0fcfe1ed0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before stripping: ['Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?', \"I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\"]\n",
            "Post stripping: ['Astrology I am a Capricorn Sun Cap moon and cap risingwhat does that say about me']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The actual text encoder & padder"
      ],
      "metadata": {
        "id": "JznY2PFKRUQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class SentenceVectorizer:\n",
        "    \"\"\"\n",
        "    Custom word-level text encoder\n",
        "    \"\"\"\n",
        "    #Initializing needed variables\n",
        "    def __init__(self, pad_token=\"\", unk_token=\"[UNK]\"):\n",
        "        self.pad_token = pad_token\n",
        "        self.unk_token = unk_token\n",
        "        self.word2idx = {pad_token: 0, unk_token: 1}\n",
        "        self.idx2word = {0: pad_token, 1: unk_token}\n",
        "        self.vocab = [pad_token, unk_token]\n",
        "\n",
        "\n",
        "    def fit(self, sentences):\n",
        "        #Converting the single string if passed to a list for further processing\n",
        "        if isinstance(sentences, str):\n",
        "            sentences = [sentences]\n",
        "\n",
        "        #Stripping punctuation\n",
        "        sentences = strip_punctuation(sentences)\n",
        "\n",
        "        #Populating the dictionary with our vocabulary\n",
        "        word_counts = Counter(word for sentence in sentences for word in sentence.split())\n",
        "        for word, _ in word_counts.items():\n",
        "            if word not in self.word2idx:\n",
        "                self.word2idx[word] = len(self.word2idx)\n",
        "                self.idx2word[len(self.idx2word)] = word\n",
        "                self.vocab.append(word)\n",
        "\n",
        "\n",
        "    def transform(self, sentences):\n",
        "        #Same here as in the previous method\n",
        "        if isinstance(sentences, str):\n",
        "            sentences = [sentences]\n",
        "\n",
        "        #Stripping punctuation\n",
        "        sentences = strip_punctuation(sentences)\n",
        "\n",
        "        #Vectorizing the words by pulling the values from the dictionary, if none is found -> assign the UNK token\n",
        "        vectorized = [[self.word2idx.get(word, self.word2idx[self.unk_token])\n",
        "                       for word in sentence.split()]\n",
        "                      for sentence in sentences]\n",
        "\n",
        "        #Padding to the biggest sequence received\n",
        "        return pad_sequence([torch.tensor(sentence) for sentence in vectorized],\n",
        "                            batch_first=True,\n",
        "                            padding_value=self.word2idx[self.pad_token])\n",
        "\n",
        "\n",
        "def get_sentence_vectorizer(sentences):\n",
        "    torch.manual_seed(33)\n",
        "\n",
        "    # Creating the object of the Vectorizer\n",
        "    sentence_vectorizer = SentenceVectorizer()\n",
        "\n",
        "    #Building vocabulary\n",
        "    sentence_vectorizer.fit(sentences)\n",
        "\n",
        "    # Get the vocabulary\n",
        "    vocab = sentence_vectorizer.vocab\n",
        "\n",
        "    return sentence_vectorizer, vocab\n",
        "\n",
        "\n",
        "#Creating the vectorizer object & vocab size\n",
        "vectorizer, vocab = get_sentence_vectorizer(np.concatenate((Q1_train, Q2_train)))\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "\n",
        "def tokenize_sentences(sentences):\n",
        "    #Tokenizing the passed sentence\n",
        "    encoded_sentences = vectorizer.transform(sentences)\n",
        "\n",
        "    return encoded_sentences"
      ],
      "metadata": {
        "id": "ua_oTqM_ppQV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocabulary size: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eujzGLkXSC8s",
        "outputId": "d722e653-2428-492c-e370-5cc3320dd98b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 36224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('first question in the train set:\\n')\n",
        "print(Q1_train[:5], '\\n')\n",
        "print('encoded version:')\n",
        "print(tokenize_sentences(Q1_train[:5]),'\\n')\n",
        "\n",
        "print('first question in the test set:\\n')\n",
        "print(Q1_test[:5], '\\n')\n",
        "print('encoded version:')\n",
        "print(tokenize_sentences(Q1_test[:5]) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWZzmtevp6_Y",
        "outputId": "688fc5f6-b2dc-4561-faa3-699ce9aeeeb4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first question in the train set:\n",
            "\n",
            "['Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?'\n",
            " 'How can I be a good geologist?'\n",
            " 'How do I read and find my YouTube comments?'\n",
            " 'What can make Physics easy to learn?'\n",
            " 'What was your first sexual experience like?'] \n",
            "\n",
            "encoded version:\n",
            "tensor([[ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
            "        [18, 19,  3, 20,  5, 21, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [18, 23,  3, 24, 10, 25, 26, 27, 28,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [29, 19, 30, 31, 32, 33, 34,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [29, 35, 36, 37, 38, 39, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0]]) \n",
            "\n",
            "first question in the test set:\n",
            "\n",
            "['How do I prepare for interviews for cse?'\n",
            " 'What is the best bicycle to buy under 10k?'\n",
            " 'How do I become Mutual funds distributer for all company mutual funds?'\n",
            " 'Will this relationship work?' 'How does Brexit affect India?'] \n",
            "\n",
            "encoded version:\n",
            "tensor([[  18,   23,    3,   70,   45,  763,   45, 9239,    0,    0,    0,    0],\n",
            "        [  29,  118,   83,  152, 7102,   33,  541,  210, 6641,    0,    0,    0],\n",
            "        [  18,   23,    3,  394, 1020,  558,    1,   45,  179, 1783, 1575,  558],\n",
            "        [ 109,  358, 1206,  219,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [  18,   13, 1433,  710,  225,    0,    0,    0,    0,    0,    0,    0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset loader"
      ],
      "metadata": {
        "id": "E9CjXCawnQNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomData(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset class that transforms all the data at init step\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sequences_Q1, sequences_Q2, labels, transform=tokenize_sentences):\n",
        "        super().__init__()\n",
        "        self.sequences_Q1 = transform(sequences_Q1)\n",
        "        self.sequences_Q2 = transform(sequences_Q2)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences_Q1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sequences_Q1[idx], self.sequences_Q2[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "inI6GUlwm8fG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Preparing the data (for train and val set labels are just placeholders,\n",
        "as we will have the custom loss (The Triplet Loss))\n",
        "\"\"\"\n",
        "\n",
        "train_set = CustomData(train_Q1, train_Q2, [1] * len(train_Q1))\n",
        "val_set = CustomData(val_Q1, val_Q2, [1] * len(val_Q1))\n",
        "test_set = CustomData(Q1_test, Q2_test, y_test)\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=512)"
      ],
      "metadata": {
        "id": "UKaqjjIFvE1z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Siamese model"
      ],
      "metadata": {
        "id": "aRuBsIk5TZkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bZxCzPAJbW2z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creating a custom L2 norm class to later use it as a layer in our NN\n",
        "\"\"\"\n",
        "class NormalizationLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.normalize(x)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Base NN class\n",
        "\"\"\"\n",
        "class BaseNetwork(nn.Module):\n",
        "    def __init__(self, text_vectorizer=tokenize_sentences, vocab_size=vocab_size, d_feature=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.Embedding = nn.Embedding(vocab_size, d_feature)\n",
        "        self.LSTM = nn.LSTM(d_feature, d_feature, batch_first=True)\n",
        "        self.AdaptiveAvgPooling = nn.AdaptiveAvgPool1d(1)\n",
        "        self.l2norm = NormalizationLayer()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Embedding(x)\n",
        "        x, _ = self.LSTM(x)\n",
        "        #Transposing to change the dimensions of the sequence length and embedding_dims\n",
        "        #So that we can global average pool over the sequence length dimension\n",
        "        x = torch.transpose(x, 1, 2)\n",
        "        x = self.AdaptiveAvgPooling(x)\n",
        "        x = self.l2norm(x)\n",
        "        #Removing the 1 dim for further shape convenience\n",
        "        x = torch.squeeze(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Siamese Network class to use the NN twice on two different inputs\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #Creating an object of the NN\n",
        "        self.nn = BaseNetwork(vectorizer, vocab_size)\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        #Two vectors of sequences\n",
        "        output1 = self.nn(input1)\n",
        "        output2 = self.nn(input2)\n",
        "\n",
        "        #Accounting for the testing phase where there's only 1 dim\n",
        "        if output1.dim() == 1:\n",
        "            conc = torch.cat((output1, output2), dim=0)\n",
        "        else:\n",
        "            conc = torch.cat((output1, output2), dim=1)\n",
        "\n",
        "        return conc"
      ],
      "metadata": {
        "id": "65qOPtaMF1D9"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SiameseNetwork().to(device)"
      ],
      "metadata": {
        "id": "tdTQaJQQH-qV"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hard negative mining"
      ],
      "metadata": {
        "id": "lUk5axl5H7fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TripletLossFn(v1, v2, margin=0.25):\n",
        "    \"\"\"\n",
        "    Custom Loss function\n",
        "    \"\"\"\n",
        "    #Cosine similarities\n",
        "    scores = torch.matmul(v2, v1.T).to(device)\n",
        "    #Row size (sample size)\n",
        "    batch_size = v1.size(0)\n",
        "    #Positives (on diagonal)\n",
        "    positive = torch.diagonal(scores).to(device)\n",
        "    #Only negatives (canceling out the positives)\n",
        "    negative_zero_on_duplicate = scores - torch.diag(positive).to(device)\n",
        "    #Calculating mean negatives\n",
        "    mean_negative = torch.sum(negative_zero_on_duplicate, dim=1) / (batch_size - 1)\n",
        "    #Masking the positives and the negatives that are bigger than the positives\n",
        "    mask_exclude_positives = (torch.eye(batch_size) == 1).to(device) | (negative_zero_on_duplicate > torch.unsqueeze(positive, 1))\n",
        "    #Extracting the masked elements from the original matrix\n",
        "    negative_without_positives = negative_zero_on_duplicate - mask_exclude_positives * 2\n",
        "    #Finding the closest negative\n",
        "    closest_negative = torch.max(negative_without_positives, dim=1).values\n",
        "    #Triplet loss 1\n",
        "    triplet_loss1 = torch.maximum(-(positive) + closest_negative + margin, torch.tensor(0))\n",
        "    #Triples loss 2\n",
        "    triplet_loss2 = torch.maximum(-(positive) + mean_negative + margin, torch.tensor(0))\n",
        "    #Triplet loss 3\n",
        "    triplet_loss3 = torch.sum(triplet_loss1 + triplet_loss2)\n",
        "\n",
        "    return triplet_loss3"
      ],
      "metadata": {
        "id": "zuFbGCY9aqLs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = torch.tensor([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
        "v2 = torch.tensor([[ 0.26726124,  0.53452248, 0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\n",
        "print(\"Triplet Loss:\", TripletLossFn(v1,v2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7450TW60HFsE",
        "outputId": "ff104829-55b7-461b-a8e0-d8bf635141b7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Triplet Loss: tensor(0.7035, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def TripletLoss(labels, output, margin=0.25):\n",
        "    \"\"\"\n",
        "    Extracting the two tensors of sequences received from the model\n",
        "    so that we can compute the Triplet loss on the two sequences\n",
        "    \"\"\"\n",
        "    _, embedding_dim = output.size()\n",
        "    v1 = output[:, :int(embedding_dim / 2)]\n",
        "    v2 = output[:, int(embedding_dim / 2):]\n",
        "\n",
        "    return TripletLossFn(v1, v2, margin)"
      ],
      "metadata": {
        "id": "ZXlfWXnXfkUZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss fn, optimizer,"
      ],
      "metadata": {
        "id": "myOq8YFlRZYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = TripletLoss\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "WK16Fsb8R6au"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "kFBhv6-2RWsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 2\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for i, (data1, data2, labels) in enumerate(train_loader):\n",
        "        data1, data2, labels = data1.to(device), data2.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data1, data2)\n",
        "        loss = criterion(labels, outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 50 == 49:\n",
        "            print(f\"[{epoch + 1}, {i+1}], running_loss: {running_loss:.4f}\")\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hmYHOwqRGtd",
        "outputId": "8644ab4c-6b27-497b-f899-4d1eb281e14b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 50], running_loss: 2188.2154\n",
            "[1, 100], running_loss: 941.9193\n",
            "[1, 150], running_loss: 779.4593\n",
            "[1, 200], running_loss: 672.8524\n",
            "[1, 250], running_loss: 618.6795\n",
            "[1, 300], running_loss: 573.0292\n",
            "[2, 50], running_loss: 400.9674\n",
            "[2, 100], running_loss: 395.5428\n",
            "[2, 150], running_loss: 416.0395\n",
            "[2, 200], running_loss: 413.1872\n",
            "[2, 250], running_loss: 419.2199\n",
            "[2, 300], running_loss: 406.6781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "hqaUsrE1F4FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss = 0.0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (data1, data2, labels) in enumerate(val_loader):\n",
        "        data1, data2, labels = data1.to(device), data2.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(data1, data2)\n",
        "        loss = criterion(labels, outputs)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 20 == 19:\n",
        "            print(f\"[{i+1}], validation_loss: {running_loss:.4f}\")\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er-5F7DGFtds",
        "outputId": "cb1b9603-bb98-478a-fb02-f0a7b7b8a224"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20], validation_loss: 189.8702\n",
            "[40], validation_loss: 193.6596\n",
            "[60], validation_loss: 180.8987\n",
            "[80], validation_loss: 181.7615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "eT2K8JPHHN6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify"
      ],
      "metadata": {
        "id": "nRBuVxEwHReN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classify(threshold, model):\n",
        "    \"\"\"\n",
        "    Calculating the accuracy\n",
        "    and confusion matrix on the test set\n",
        "    \"\"\"\n",
        "    y_pred = []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs1, inputs2, y_test in test_loader:\n",
        "            inputs1, inputs2, y_test = inputs1.to(device), inputs2.to(device), y_test.to(device)\n",
        "\n",
        "            outputs = model(inputs1, inputs2)\n",
        "            _, n_feat = outputs.size()\n",
        "            #Extracting the two sequences\n",
        "            v1 = outputs[:, :int(n_feat/2)]\n",
        "            v2 = outputs[:, int(n_feat/2):]\n",
        "            #Cosine similarity\n",
        "            d = torch.sum(v1 * v2, dim=1)\n",
        "            #Checking against the threshold\n",
        "            y_pred = (d > threshold).to(dtype=torch.float64)\n",
        "            y_test = y_test.to(dtype=torch.float64)\n",
        "\n",
        "            accuracy = torch.sum((y_pred == y_test).to(dtype=torch.float32)) / len(y_test)\n",
        "\n",
        "            cm = confusion_matrix(y_test.cpu().numpy(), y_pred.cpu().numpy())\n",
        "\n",
        "            return accuracy, cm"
      ],
      "metadata": {
        "id": "XC3MRmCM00tA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, cm = classify(0.7, model)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\\n\")\n",
        "print(f\"Confusion matrix:\\n {cm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoKn-xVnf37L",
        "outputId": "c509b823-2567-478e-947c-3d875fec2b8c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.732421875\n",
            "\n",
            "Confusion matrix:\n",
            " [[257  72]\n",
            " [ 65 118]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "Sq35IE7dnko-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(question1, question2, threshold, model, verbose=False):\n",
        "    \"\"\"\n",
        "    Predicting similarity on two sequences\n",
        "    \"\"\"\n",
        "    #Encoding\n",
        "    question1 = tokenize_sentences(question1).to(device)\n",
        "    question2 = tokenize_sentences(question2).to(device)\n",
        "    #Passing to the model\n",
        "    outputs = model(question1, question2)\n",
        "    n_feat = len(outputs)\n",
        "    #Extracting two encoded sequences\n",
        "    v1 = outputs[:int(n_feat/2)]\n",
        "    v2 = outputs[int(n_feat/2):]\n",
        "    #Calculating the cosine similarity\n",
        "    d = torch.sum(v1*v2)\n",
        "    #Checking the cosine similarity against the threshold\n",
        "    res = d > threshold\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Q1 = {question1}\\n Q2 = {question2}\\n\")\n",
        "        print(f\"d = {d}\\n\")\n",
        "        print(f\"res = {res}\")\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "ncrRs8LmgBfj"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feel free to try with your own questions\n",
        "question1 = \"When will I see you?\"\n",
        "question2 = \"When can I see you again?\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, verbose = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIRmcoBKovS6",
        "outputId": "3bba3906-efb3-4f57-c686-6c044943eac7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 = tensor([[723, 230,   3, 325,  92]], device='cuda:0')\n",
            " Q2 = tensor([[ 723,   19,    3,  325,   92, 5808]], device='cuda:0')\n",
            "\n",
            "d = 0.7256489992141724\n",
            "\n",
            "res = True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feel free to try with your own questions\n",
        "question1 = \"Read a book\"\n",
        "question2 = \"Book a table\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5WjSAdfo2i5",
        "outputId": "81796aa7-4e85-4474-bf9d-2ebb3db37c13"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 = tensor([[6879,    5,  143]], device='cuda:0')\n",
            " Q2 = tensor([[4445,    5, 5413]], device='cuda:0')\n",
            "\n",
            "d = 0.34251832962036133\n",
            "\n",
            "res = False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ]
}
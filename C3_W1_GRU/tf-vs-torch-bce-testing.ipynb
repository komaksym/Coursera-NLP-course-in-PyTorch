{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-24T18:29:54.384158Z","iopub.execute_input":"2024-08-24T18:29:54.384599Z","iopub.status.idle":"2024-08-24T18:29:54.414790Z","shell.execute_reply.started":"2024-08-24T18:29:54.384547Z","shell.execute_reply":"2024-08-24T18:29:54.413504Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Global vars","metadata":{}},{"cell_type":"code","source":"batch_size = 5\nnum_epochs = 20\nn_embeddings = 45\nembedding_dim = 8","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:29:54.417386Z","iopub.execute_input":"2024-08-24T18:29:54.417861Z","iopub.status.idle":"2024-08-24T18:29:54.423480Z","shell.execute_reply.started":"2024-08-24T18:29:54.417810Z","shell.execute_reply":"2024-08-24T18:29:54.422392Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"X = [[2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 8, 20, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [22, 23, 24, 8, 25, 26, 27, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [29, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 8, 42, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\ny = [[1], [1], [1], [1], [1]]","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:29:54.425276Z","iopub.execute_input":"2024-08-24T18:29:54.425700Z","iopub.status.idle":"2024-08-24T18:29:54.449159Z","shell.execute_reply.started":"2024-08-24T18:29:54.425661Z","shell.execute_reply":"2024-08-24T18:29:54.447488Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# WEIGHTS","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nnp.random.seed(2024)\n\nembedding_weights = np.random.rand(n_embeddings, embedding_dim).astype(np.float32)\nkernel_weights = np.random.rand(embedding_dim, 1).astype(np.float32)\nkernel_biases = np.zeros(1).astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:29:54.456562Z","iopub.execute_input":"2024-08-24T18:29:54.457456Z","iopub.status.idle":"2024-08-24T18:29:54.471551Z","shell.execute_reply.started":"2024-08-24T18:29:54.457392Z","shell.execute_reply":"2024-08-24T18:29:54.469645Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# TENSORFLOW","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n#----------------MODEL-----------------------\ntf_model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(n_embeddings, embedding_dim, weights=[embedding_weights], input_length=51),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(1, activation='sigmoid', \n                         kernel_initializer=tf.keras.initializers.Constant(kernel_weights),\n                         bias_initializer=tf.keras.initializers.Constant(kernel_biases))\n])\n\n#----------------END OF MODEL----------------","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:29:54.474725Z","iopub.execute_input":"2024-08-24T18:29:54.475461Z","iopub.status.idle":"2024-08-24T18:30:09.512481Z","shell.execute_reply.started":"2024-08-24T18:29:54.475410Z","shell.execute_reply":"2024-08-24T18:30:09.511290Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport random\n\n#----------------OPTIMIZER & LOSS----------------\ntf_model.compile(loss='binary_crossentropy',\n              optimizer=tf.keras.optimizers.Adam()\n             )\n#----------------OPTIMIZER & LOSS----------------\n\n\n#----------------DATA----------------\n# Prepare the data\ntrain_x_prepared = np.array(X)\ntrain_y_prepared = np.array(y)\n\nprint('The data is prepared for training!\\n')\n#----------------DATA----------------\n\n\n#----------------TRAINING----------------\nprint('Training:')\nhistory = tf_model.fit(train_x_prepared, train_y_prepared, batch_size=batch_size, epochs=num_epochs)\n#----------------TRAINING----------------","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:30:09.514234Z","iopub.execute_input":"2024-08-24T18:30:09.515015Z","iopub.status.idle":"2024-08-24T18:30:11.178685Z","shell.execute_reply.started":"2024-08-24T18:30:09.514961Z","shell.execute_reply":"2024-08-24T18:30:11.177259Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The data is prepared for training!\n\nTraining:\nEpoch 1/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910ms/step - loss: 0.1064\nEpoch 2/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1006\nEpoch 3/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0951\nEpoch 4/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0898\nEpoch 5/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0848\nEpoch 6/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0802\nEpoch 7/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0757\nEpoch 8/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0716\nEpoch 9/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0676\nEpoch 10/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0639\nEpoch 11/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0605\nEpoch 12/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0572\nEpoch 13/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0542\nEpoch 14/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0513\nEpoch 15/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0486\nEpoch 16/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0461\nEpoch 17/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0437\nEpoch 18/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0415\nEpoch 19/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0395\nEpoch 20/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0375\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# PyTorch","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import optim\nfrom torch import nn\n\n\n#----------------MODEL----------------\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embedding = nn.Embedding(n_embeddings, embedding_dim)\n        self.pooling = nn.AdaptiveAvgPool1d(1)\n        self.fc = nn.Linear(embedding_dim, 1)\n        self.activation = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = x.permute(0, 2, 1)\n        x = self.pooling(x)\n        x = x.squeeze(2)\n        x = self.fc(x)\n        x = self.activation(x)\n        return x\n\npt_model = Net()\n\n# Set the embedding weights\npt_model.embedding.weight.data = torch.from_numpy(embedding_weights)\n\n# Set the linear layer weights and bias\npt_model.fc.weight.data = torch.from_numpy(kernel_weights.T)\npt_model.fc.bias.data = torch.from_numpy(kernel_biases)\n#----------------MODEL----------------\n\n\n#----------------OPTIMIZER & LOSS----------------\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(pt_model.parameters(), eps=1e-07)\n#----------------OPTIMIZER & LOSS----------------\n\n\n#----------------DATA----------------\ntorch_train_x_prepared = torch.tensor(X).long()\ntorch_train_y_prepared = torch.tensor(y).float()\n\nprint('The data is prepared for training!\\n')\n#----------------DATA----------------\n\n\n#----------------TRAINING----------------\nprint('Training:')\n\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n\n    for i in range(0, len(torch_train_x_prepared), batch_size):\n        batch_x = torch_train_x_prepared[i:i+batch_size]\n        batch_y = torch_train_y_prepared[i:i+batch_size]\n        \n        optimizer.zero_grad()\n        outputs = pt_model(batch_x)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch: {epoch+1}/{num_epochs}, loss: {running_loss / (len(torch_train_x_prepared) / batch_size)}\")\n\nprint(\"Training is finished\")\n#----------------TRAINING----------------","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:30:11.180904Z","iopub.execute_input":"2024-08-24T18:30:11.181562Z","iopub.status.idle":"2024-08-24T18:30:15.941778Z","shell.execute_reply.started":"2024-08-24T18:30:11.181518Z","shell.execute_reply":"2024-08-24T18:30:15.940562Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"The data is prepared for training!\n\nTraining:\nEpoch: 1/20, loss: 0.10643015801906586\nEpoch: 2/20, loss: 0.1055297702550888\nEpoch: 3/20, loss: 0.10463515669107437\nEpoch: 4/20, loss: 0.10374639183282852\nEpoch: 5/20, loss: 0.10286366939544678\nEpoch: 6/20, loss: 0.10198686271905899\nEpoch: 7/20, loss: 0.10111621767282486\nEpoch: 8/20, loss: 0.1002516895532608\nEpoch: 9/20, loss: 0.09939347207546234\nEpoch: 10/20, loss: 0.09854154288768768\nEpoch: 11/20, loss: 0.09769599139690399\nEpoch: 12/20, loss: 0.09685685485601425\nEpoch: 13/20, loss: 0.09602418541908264\nEpoch: 14/20, loss: 0.09519802033901215\nEpoch: 15/20, loss: 0.09437845647335052\nEpoch: 16/20, loss: 0.09356546401977539\nEpoch: 17/20, loss: 0.09275911748409271\nEpoch: 18/20, loss: 0.09195945411920547\nEpoch: 19/20, loss: 0.09116645902395248\nEpoch: 20/20, loss: 0.09038019925355911\nTraining is finished\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_x_prepared.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:30:15.943347Z","iopub.execute_input":"2024-08-24T18:30:15.944297Z","iopub.status.idle":"2024-08-24T18:30:15.950091Z","shell.execute_reply.started":"2024-08-24T18:30:15.944255Z","shell.execute_reply":"2024-08-24T18:30:15.948835Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(5, 51)\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_layer = model.layers[0]\nembedding_layer_weights = embedding_layer.get_weights()\n\nprint(type(embedding_layer_weights[0]))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:30:15.951664Z","iopub.execute_input":"2024-08-24T18:30:15.952112Z","iopub.status.idle":"2024-08-24T18:30:16.299167Z","shell.execute_reply.started":"2024-08-24T18:30:15.952048Z","shell.execute_reply":"2024-08-24T18:30:16.297597Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embedding_layer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m embedding_layer_weights \u001b[38;5;241m=\u001b[39m embedding_layer\u001b[38;5;241m.\u001b[39mget_weights()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(embedding_layer_weights[\u001b[38;5;241m0\u001b[39m]))\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"\"\"\"# Example 1: (batch_size = 1, number of samples = 4)\ny_true = np.array([0, 1, 0, 0])\ny_pred = np.array([-18.6, 0.51, 2.94, -12.8])\nbce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nbce(y_true, y_pred)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:30:16.300259Z","iopub.status.idle":"2024-08-24T18:30:16.300671Z","shell.execute_reply.started":"2024-08-24T18:30:16.300477Z","shell.execute_reply":"2024-08-24T18:30:16.300497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"## Example 1: (batch_size = 1, number of samples = 4)\ny_true = torch.tensor([0, 1, 0, 0], dtype=torch.float)\ny_pred = torch.tensor([-18.6, 0.51, 2.94, -12.8], dtype=torch.float)\nbce = nn.BCEWithLogitsLoss()\n\nbce(y_pred, y_true)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-24T18:30:16.302493Z","iopub.status.idle":"2024-08-24T18:30:16.303074Z","shell.execute_reply.started":"2024-08-24T18:30:16.302780Z","shell.execute_reply":"2024-08-24T18:30:16.302809Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
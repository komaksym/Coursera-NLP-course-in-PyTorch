{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUKy8nOCj_R3"
      },
      "source": [
        "# Drive files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsmGLGoTjaj1",
        "outputId": "61d54327-9d47-4f93-b25e-3ef8777a3f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJgN2hYvjmPJ",
        "outputId": "d8fc327f-a780-4b0a-bb8f-347fd3762ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SequenceModelsCoursera/W1_Test3/tf\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/SequenceModelsCoursera/W1_Test3/tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDkwzszPj-ac"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "3sGHjohejNUI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXvOPeYGkZGo"
      },
      "source": [
        "# Exploring the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIb3fxprkdOl",
        "outputId": "65ff6cd9-458d-4818-ffbd-952117b9f8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SENTENCE: Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
            "\n",
            "SENTENCE LABEL: O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
            "\n",
            "ORIGINAL DATA:\n",
            "     Sentence #           Word  POS Tag\n",
            "0  Sentence: 1      Thousands  NNS   O\n",
            "1          NaN             of   IN   O\n",
            "2          NaN  demonstrators  NNS   O\n",
            "3          NaN           have  VBP   O\n",
            "4          NaN        marched  VBN   O\n"
          ]
        }
      ],
      "source": [
        "# display original kaggle data\n",
        "#Reading pandas df\n",
        "data = pd.read_csv(\"data/ner_dataset.csv\", encoding = \"ISO-8859-1\")\n",
        "\n",
        "#Reading datasets from OS\n",
        "train_sents = open('data/small/train/sentences.txt', 'r').readline()\n",
        "train_labels = open('data/small/train/labels.txt', 'r').readline()\n",
        "print('SENTENCE:', train_sents)\n",
        "print('SENTENCE LABEL:', train_labels)\n",
        "print('ORIGINAL DATA:\\n', data.head())\n",
        "#Deleting from memory just in case\n",
        "del(data, train_sents, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo6HUnXyTpDJ"
      },
      "source": [
        "## Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "S7oJb-8gTszo"
      },
      "outputs": [],
      "source": [
        "#Read data\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = [line.strip() for line in file.readlines()]\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "LcM_Uh4LVECY"
      },
      "outputs": [],
      "source": [
        "#Load the datasets from the google drive\n",
        "train_sentences = load_data('/content/drive/MyDrive/SequenceModelsCoursera/W1_Test3/tf/data/large/train/sentences.txt')\n",
        "train_labels = load_data('/content/drive/MyDrive/SequenceModelsCoursera/W1_Test3/tf/data/large/train/labels.txt')\n",
        "\n",
        "val_sentences = load_data('/content/drive/MyDrive/SequenceModelsCoursera/W1_Test3/tf/data/large/val/sentences.txt')\n",
        "val_labels = load_data('/content/drive/MyDrive/SequenceModelsCoursera/W1_Test3/tf/data/large/val/labels.txt')\n",
        "\n",
        "test_sentences = load_data('/content/drive/MyDrive/SequenceModelsCoursera/W1_Test3/tf/data/large/test/sentences.txt')\n",
        "test_labels = load_data('/content/drive/MyDrive/SequenceModelsCoursera/W1_Test3/tf/data/large/test/labels.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn1ZLKofV1BK"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from collections import Counter\n",
        "\n",
        "class SentenceVectorizer:\n",
        "    \"\"\"\n",
        "    Custom word-level text encoder\n",
        "    \"\"\"\n",
        "\n",
        "    #Initializing needed variables\n",
        "    def __init__(self, pad_token=\"\", unk_token=\"[UNK]\"):\n",
        "        self.pad_token = pad_token\n",
        "        self.unk_token = unk_token\n",
        "        self.word2idx = {pad_token: 0, unk_token: 1}\n",
        "        self.idx2word = {0: pad_token, 1: unk_token}\n",
        "        self.vocab = [pad_token, unk_token]\n",
        "\n",
        "\n",
        "    def fit(self, sentences):\n",
        "        #Converting the single string if passed to a list for further processing\n",
        "        if isinstance(sentences, str):\n",
        "            sentences = [sentences]\n",
        "\n",
        "        #Populating the dictionary with our vocabulary\n",
        "        word_counts = Counter(word for sentence in sentences for word in sentence.split())\n",
        "        for word, _ in word_counts.items():\n",
        "            if word not in self.word2idx:\n",
        "                self.word2idx[word] = len(self.word2idx)\n",
        "                self.idx2word[len(self.idx2word)] = word\n",
        "                self.vocab.append(word)\n",
        "\n",
        "\n",
        "    def transform(self, sentences):\n",
        "        if isinstance(sentences, str):\n",
        "            sentences = [sentences]\n",
        "\n",
        "        #Vectorizing the words by pulling the values from the dictionary, if none is found -> assign the UNK token\n",
        "        vectorized = [[self.word2idx.get(word, self.word2idx[self.unk_token])\n",
        "                       for word in sentence.split()]\n",
        "                      for sentence in sentences]\n",
        "\n",
        "        #Padding to the biggest sequence received\n",
        "        return pad_sequence([torch.tensor(sentence) for sentence in vectorized],\n",
        "                            batch_first=True,\n",
        "                            padding_value=self.word2idx[self.pad_token])\n",
        "\n",
        "\n",
        "def get_sentence_vectorizer(sentences):\n",
        "    torch.manual_seed(33)\n",
        "\n",
        "    # Creating the object of the Vectorizer\n",
        "    sentence_vectorizer = SentenceVectorizer()\n",
        "\n",
        "    #Building vocabulary\n",
        "    sentence_vectorizer.fit(sentences)\n",
        "\n",
        "    # Get the vocabulary\n",
        "    vocab = sentence_vectorizer.vocab\n",
        "\n",
        "    return sentence_vectorizer, vocab"
      ],
      "metadata": {
        "id": "0pAzvirGPa25"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the vectorizer object\n",
        "vectorizer, vocab = get_sentence_vectorizer(train_sentences)\n",
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "SFqsKtDESrh5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentences(sentences):\n",
        "    #Tokenizing the passed sentence\n",
        "    encoded_sentences = vectorizer.transform(sentences)\n",
        "\n",
        "    return encoded_sentences"
      ],
      "metadata": {
        "id": "54XWegVlSmOf"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sentences\n",
        "sentence = \"Many French citizens are goin to visit Morocco for summer\"\n",
        "\n",
        "print(f\"Sentence {sentence}\")\n",
        "\n",
        "# Vectorize the sentences\n",
        "vectorized_sentences = tokenize_sentences(sentence)\n",
        "\n",
        "print(\"\\nVectorized sentences:\")\n",
        "print(vectorized_sentences)\n",
        "\n",
        "print(\"\\nShape of vectorized sentences:\")\n",
        "print(vectorized_sentences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjLAO82qQSoB",
        "outputId": "bafabfdb-ee0c-4ed5-ceb8-4b860f0bfafe"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Many French citizens are goin to visit Morocco for summer\n",
            "Encoded sentence shape: torch.Size([1, 10])\n",
            "\n",
            "Vectorized sentences:\n",
            "tensor([[4284,  855, 1789,  182,    1,    9, 2354, 8377,  225, 6483]])\n",
            "\n",
            "Shape of vectorized sentences:\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBAATYNUWFA4"
      },
      "source": [
        "## Encoding the sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocab size\n",
        "vocab_size = len(set(word for sentence in train_sentences for word in sentence.split()))"
      ],
      "metadata": {
        "id": "JSQqpply7zN5"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqrs1_V7Dezg"
      },
      "source": [
        "## Encoding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ele-hrs4Dg7F",
        "outputId": "f509bc7e-651e-4c1e-d754-6c4d591f6480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences: Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
            "Labels: O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n"
          ]
        }
      ],
      "source": [
        "print(f\"Sentences: {train_sentences[0]}\")\n",
        "print(f\"Labels: {train_labels[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "sPgEsZdtDqDI"
      },
      "outputs": [],
      "source": [
        "#Creating a set of all possible tags\n",
        "def get_tags(labels):\n",
        "    tags = set(tag for tags in labels for tag in tags.split())\n",
        "    tags = list(tags)\n",
        "    tags.sort()\n",
        "\n",
        "    return tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "KFnV3951DwA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b316be15-f9dc-4f0a-9038-95b2b05f6696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ],
      "source": [
        "#Creating a set of tags and saving it in a variable\n",
        "tags = get_tags(train_labels)\n",
        "num_tags = len(tags)\n",
        "print(num_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "VzzW_SrIDz2_"
      },
      "outputs": [],
      "source": [
        "#Mapping each tag to a unique integer to encode the labels later\n",
        "def make_tag_map(tags):\n",
        "    tag_map = {}\n",
        "\n",
        "    for i, tag in enumerate(tags):\n",
        "        tag_map[tag] = i\n",
        "\n",
        "    return tag_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXgsPD_6FNMC",
        "outputId": "573ec10b-4953-4a59-d5b4-38f553ccd861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16}\n"
          ]
        }
      ],
      "source": [
        "# #Mapping each tag to a unique integer to encode the labels later (saving into a var)\n",
        "tag_map = make_tag_map(tags)\n",
        "print(tag_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rZSUw9lFXER"
      },
      "source": [
        "## Encoding labels (this time fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New"
      ],
      "metadata": {
        "id": "Ryg0ulXuU1rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "    #Create an encoded version of tags for a sample and pad them with -1 to the size of the biggest sequence present.\n",
        "\n",
        "def label_vectorizer(labels, tags_map):\n",
        "    #Iterating over each labels sample\n",
        "    total_element_ids = []\n",
        "\n",
        "    #Checking if input is a list of strings\n",
        "    if isinstance(labels, list) and all(isinstance(item, str) for item in labels):\n",
        "        for label in labels:\n",
        "            element_ids = []\n",
        "            tokens = label.split()\n",
        "\n",
        "            #Iterating over each token in the same sequence targets\n",
        "            for token in tokens:\n",
        "                element_ids.append(tags_map[token])\n",
        "\n",
        "            # Adding the encoded ids of one sample to the main list\n",
        "            total_element_ids.append(element_ids)\n",
        "\n",
        "    #Checking if the input is a single string\n",
        "    elif isinstance(labels, str):\n",
        "        element_ids = []\n",
        "        tokens = labels.split()\n",
        "\n",
        "        for token in tokens:\n",
        "            element_ids.append(tags_map[token])\n",
        "\n",
        "    #Padding\n",
        "    padded_ids = torch.nn.utils.rnn.pad_sequence([torch.tensor(sequence) for sequence in total_element_ids],\n",
        "                                                        batch_first=True, padding_value=-1)\n",
        "\n",
        "    return padded_ids"
      ],
      "metadata": {
        "id": "WuQpREm7Uy4R"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sentence: {train_sentences[:6]}\")\n",
        "print(f\"Vectorized labels: {label_vectorizer(train_labels[:6], tag_map)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xCThOmqVcW2",
        "outputId": "02f5fe59-564a-4af1-fc2f-beff54e7a46b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: ['Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .', 'Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"', 'They marched from the Houses of Parliament to a rally in Hyde Park .', 'Police put the number of marchers at 10,000 while organizers claimed it was 1,00,000 .', \"The protest comes on the eve of the annual conference of Britain 's ruling Labor Party in the southern English seaside resort of Brighton .\", \"The party is divided over Britain 's participation in the Iraq conflict and the continued deployment of 8,500 British troops in that country .\"]\n",
            "Vectorized labels: tensor([[16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16,\n",
            "          3, 16, 16, 16, 16, 16, -1, -1, -1, -1, -1, -1],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "          6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 10, 16, -1, -1, -1, -1,\n",
            "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, -1, -1, -1,\n",
            "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16,  5, 13, 16, 16,\n",
            "         16,  3, 16, 16, 16,  2, 16, -1, -1, -1, -1, -1],\n",
            "        [16, 16, 16, 16, 16,  3, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16,\n",
            "          3, 16, 16, 16, 16, 16, -1, -1, -1, -1, -1, -1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6isbvkkYhiqX"
      },
      "source": [
        "# Building the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "LQyT7ON3LdW-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sentences, labels, transform=tokenize_sentences, label_transform=label_vectorizer, tag_map=tag_map):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        self.label_transform = label_transform\n",
        "        self.tag_map = tag_map\n",
        "\n",
        "        #Encoding our data\n",
        "        self.sentences = self.transform(sentences)\n",
        "        self.labels = self.label_transform(labels, self.tag_map)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.sentences[idx]\n",
        "        labels = self.labels[idx]\n",
        "\n",
        "        return sequence, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "FZBWC_R0YyZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe88788-725d-40c5-9835-e34e5fa4b7f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded sentence shape: torch.Size([33570, 104])\n",
            "Encoded sentence shape: torch.Size([7194, 73])\n",
            "Encoded sentence shape: torch.Size([7194, 70])\n"
          ]
        }
      ],
      "source": [
        "#Creating datasets\n",
        "train_dataset = CustomDataset(train_sentences, train_labels)\n",
        "val_dataset = CustomDataset(val_sentences, val_labels)\n",
        "test_dataset = CustomDataset(test_sentences, test_labels)\n",
        "\n",
        "#Dataloaders for batching\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = next(iter(train_loader))\n",
        "\n",
        "print(f\"Train Data shape: {data.size()}\")\n",
        "print(f\"Train Labels shape: {labels.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR9x2SfuCcCE",
        "outputId": "7179fdae-04c4-4376-9253-4661fe6ad3cb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data shape: torch.Size([64, 104])\n",
            "Train Labels shape: torch.Size([64, 104])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = next(iter(val_loader))\n",
        "\n",
        "print(f\"Validation Data shape: {data.size()}\")\n",
        "print(f\"Validation Labels shape: {labels.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0orqJYpzCbbY",
        "outputId": "204651bb-db16-48ee-c6a4-84812e3784be"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Data shape: torch.Size([64, 73])\n",
            "Validation Labels shape: torch.Size([64, 73])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = next(iter(test_loader))\n",
        "\n",
        "print(f\"Test Data shape: {data.size()}\")\n",
        "print(f\"Test Labels shape: {labels.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvIPnQH38UdT",
        "outputId": "e70e30e4-8f62-44e0-8969-bcab7bf0a3ae"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Data shape: torch.Size([64, 70])\n",
            "Test Labels shape: torch.Size([64, 70])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6MO28grnSrj",
        "outputId": "4d07a3db-fb95-4943-c2c8-3a3492ca4899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of outputs is 17\n",
            "Num of vocabulary words in the training set: 29845\n",
            "The training size is 33570\n",
            "The validation size is 7194\n",
            "An example of the first sentence is\n",
            "\t tensor([[   63,  6461,  3717,  ...,     0,     0,     0],\n",
            "        [ 6504,  1491,    95,  ...,     0,     0,     0],\n",
            "        [   63,   554,   818,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [ 2913,    18,    25,  ...,     0,     0,     0],\n",
            "        [16155, 16156,   117,  ...,     0,     0,     0],\n",
            "        [13211, 10169,  4943,  ...,     0,     0,     0]])\n",
            "An example of its corresponding label is\n",
            "\t tensor([[16, 16, 16,  ..., -1, -1, -1],\n",
            "        [ 6, 14, 16,  ..., -1, -1, -1],\n",
            "        [16, 16, 16,  ..., -1, -1, -1],\n",
            "        ...,\n",
            "        [16, 16, 16,  ..., -1, -1, -1],\n",
            "        [16, 16, 16,  ..., -1, -1, -1],\n",
            "        [16, 16, 16,  ..., -1, -1, -1]])\n"
          ]
        }
      ],
      "source": [
        "# Exploring information about the training data\n",
        "print(f'The number of outputs is {len(tag_map)}')\n",
        "\n",
        "# The number of vocabulary tokens (including <PAD>)\n",
        "g_vocab_size = vocab_size\n",
        "print(f\"Num of vocabulary words in the training set: {g_vocab_size}\")\n",
        "print('The training size is', len(train_dataset))\n",
        "print('The validation size is', len(val_dataset))\n",
        "print('An example of the first sentence is\\n\\t', next(iter(train_loader))[0])\n",
        "print('An example of its corresponding label is\\n\\t', next(iter(train_loader))[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLsSKMpSwP7J"
      },
      "source": [
        "# Building a NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "LxiO6Tj53r1i"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Gxw6bqfSwTbM"
      },
      "outputs": [],
      "source": [
        "class NER(nn.Module):\n",
        "    def __init__(self, vocab_size = vocab_size, num_tags=num_tags, embedding_dim=50):\n",
        "        super().__init__()\n",
        "\n",
        "        #Defining a neural net\n",
        "        self.embedding = nn.Embedding(vocab_size+2, embedding_dim, padding_idx=0)\n",
        "        self.LSTM = nn.LSTM(embedding_dim, embedding_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(embedding_dim, num_tags)\n",
        "        self.activation = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Defining NN's forward prop\n",
        "        #print(f\"just passed x shape: {x.size()}\\n\")\n",
        "        x = self.embedding(x)\n",
        "        #print(f\"embedded x shape: {x.size()}\\n\")\n",
        "        x, _ = self.LSTM(x)\n",
        "        #print(f\"post LSTM x shape: {x.size()}\\n\")\n",
        "        x = self.fc(x)\n",
        "        #print(f\"post fc x shape: {x.size()}\\n\")\n",
        "        outputs = self.activation(x)\n",
        "        #print(f\"post activated outputs shape: {outputs.size()}\\n\")\n",
        "        outputs = outputs.transpose(1, 2)  # New shape: [64, 17, 154]\n",
        "\n",
        "        return outputs.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "H1w-l5hm4Tsb"
      },
      "outputs": [],
      "source": [
        "#Creating a model\n",
        "model = NER(vocab_size, len(tag_map)).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2RcNm5ZKPgV"
      },
      "source": [
        "## Masked loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "7CYanZVdLLUO"
      },
      "outputs": [],
      "source": [
        "#Defining a loss function (ignoreing padding indices -1)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the loss function\n",
        "true_labels = torch.tensor([0,1,2,0])\n",
        "predicted_logits = torch.tensor([[-2.3,-0.51,-1.20] , [-1.61,-0.36,-2.30], [-2.30, -0.69,-0.92], [-0.92,-0.92,-1.61]])\n",
        "print(loss_fn(predicted_logits, true_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owWtpLwn3uKM",
        "outputId": "b5f27f85-40f8-4bba-f20b-b94de7ee6bb3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1243)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masked accuracy"
      ],
      "metadata": {
        "id": "15492Ueh3XyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "iozdWSE5LScZ"
      },
      "outputs": [],
      "source": [
        "def masked_accuracy(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    Defining a masked loss function that will account for padded values and will cancel them out\n",
        "    \"\"\"\n",
        "    y_true = y_true.to(dtype=torch.float).to(device)\n",
        "\n",
        "    #Creating a mask to detect padded values and cancel them out\n",
        "    mask = torch.eq(y_true, -1)\n",
        "    mask = 1 - mask.to(dtype=torch.float).to(device)\n",
        "\n",
        "    #Extracting actual labels from logits\n",
        "    y_pred_class = y_pred.to(dtype=torch.float).to(device)\n",
        "    y_pred_class = torch.argmax(y_pred_class, dim=-2)\n",
        "\n",
        "    #Checking the # of correctly predicted values\n",
        "    matches_true_pred = torch.eq(y_pred_class, y_true)\n",
        "    matches_true_pred = matches_true_pred.to(dtype=torch.float).to(device)\n",
        "\n",
        "    #Canceling out the padded values (mask)\n",
        "    matches_true_pred *= mask\n",
        "\n",
        "    #Calculating accuracy\n",
        "    masked_acc = torch.sum(matches_true_pred) / torch.sum(mask)\n",
        "\n",
        "    return masked_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = torch.tensor([0,1,2,0])\n",
        "predicted_logits = torch.tensor([[0.1,0.6,0.3] , [0.2,0.7,0.1], [0.1, 0.5,0.4], [0.4,0.4,0.2]])\n",
        "predicted_logits = torch.transpose(predicted_logits, 0, 1)\n",
        "print(masked_accuracy(predicted_logits, true_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTMhUeZE8Hz1",
        "outputId": "888358bf-4830-43ad-d8bb-41f1b9b261a4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer & Loss"
      ],
      "metadata": {
        "id": "qIx8GVtmGNVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params = model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "metric = masked_accuracy"
      ],
      "metadata": {
        "id": "PD-VbG8cGMih"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "whgWqFxOFgad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        #print(f\"labels size: {labels.size()}\")\n",
        "\n",
        "        #Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #Forward prop\n",
        "        outputs = model(inputs)\n",
        "        #print(f\"Outputs shape: {outputs.size()}\")\n",
        "        loss = criterion(outputs, labels)\n",
        "        accuracy = metric(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #Print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 50 == 49:\n",
        "            print(f'[{epoch + 1}, {i + 1}] masked loss: {running_loss / 2000:.4f}, masked accuracy: {accuracy:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpWb7P2p8TJa",
        "outputId": "2623628e-6054-4a7a-d32f-220ac99f4475"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 50] masked loss: 0.0222, masked accuracy: 0.8497\n",
            "[1, 100] masked loss: 0.0115, masked accuracy: 0.9255\n",
            "[1, 150] masked loss: 0.0083, masked accuracy: 0.9355\n",
            "[1, 200] masked loss: 0.0065, masked accuracy: 0.9179\n",
            "[1, 250] masked loss: 0.0057, masked accuracy: 0.9359\n",
            "[1, 300] masked loss: 0.0053, masked accuracy: 0.9492\n",
            "[1, 350] masked loss: 0.0048, masked accuracy: 0.9518\n",
            "[1, 400] masked loss: 0.0044, masked accuracy: 0.9417\n",
            "[1, 450] masked loss: 0.0042, masked accuracy: 0.9469\n",
            "[1, 500] masked loss: 0.0041, masked accuracy: 0.9546\n",
            "[2, 50] masked loss: 0.0033, masked accuracy: 0.9605\n",
            "[2, 100] masked loss: 0.0033, masked accuracy: 0.9531\n",
            "[2, 150] masked loss: 0.0031, masked accuracy: 0.9713\n",
            "[2, 200] masked loss: 0.0032, masked accuracy: 0.9570\n",
            "[2, 250] masked loss: 0.0031, masked accuracy: 0.9622\n",
            "[2, 300] masked loss: 0.0031, masked accuracy: 0.9634\n",
            "[2, 350] masked loss: 0.0030, masked accuracy: 0.9717\n",
            "[2, 400] masked loss: 0.0032, masked accuracy: 0.9616\n",
            "[2, 450] masked loss: 0.0030, masked accuracy: 0.9636\n",
            "[2, 500] masked loss: 0.0031, masked accuracy: 0.9540\n",
            "Finished training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "Fcki1T5DvCL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "running_val_loss = 0.0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(val_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        accuracy = metric(outputs, labels)\n",
        "\n",
        "        running_val_loss += loss.item()\n",
        "\n",
        "        if i % 20 == 19:\n",
        "            print(f\"[{i + 1}] masked loss: {running_val_loss:.4f}, masked val accuracy: {accuracy:.4f}\")\n",
        "            running_val_loss = 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ql9a87Ju_Cs",
        "outputId": "9b787c41-894f-4bf8-b86f-f999034245d3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20] masked loss: 4.1505, masked val accuracy: 0.9441\n",
            "[40] masked loss: 3.9000, masked val accuracy: 0.9572\n",
            "[60] masked loss: 3.6106, masked val accuracy: 0.9541\n",
            "[80] masked loss: 3.9606, masked val accuracy: 0.9481\n",
            "[100] masked loss: 3.4380, masked val accuracy: 0.9635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on our own sentence"
      ],
      "metadata": {
        "id": "GtKBWkgXKww-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_map_reverse(tag_map):\n",
        "    \"\"\"\n",
        "    Mapping indices to Named Entity tags\n",
        "    \"\"\"\n",
        "    tag_map_reverse = {}\n",
        "\n",
        "    for tag, idx in tag_map.items():\n",
        "        tag_map_reverse[idx] = tag\n",
        "\n",
        "    return tag_map_reverse\n",
        "\n",
        "\n",
        "idx_to_tags = tag_map_reverse(tag_map)"
      ],
      "metadata": {
        "id": "MZ9V6vrmanLC"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence, model, sentence_vectorizer, tag_map):\n",
        "    \"\"\"\n",
        "    Predicting NER tags on a custom function\n",
        "    \"\"\"\n",
        "    vectorized_sentence = sentence_vectorizer(sentence)\n",
        "    print(vectorized_sentence.size())\n",
        "\n",
        "    outputs = model(vectorized_sentence.to(device))\n",
        "    print(outputs.size())\n",
        "\n",
        "    tag_ids = torch.argmax(outputs, axis=1)\n",
        "    tag_ids = torch.squeeze(tag_ids, dim=0)\n",
        "\n",
        "    tag_predictions = []\n",
        "\n",
        "    for id in tag_ids:\n",
        "        tag_predictions.append(tag_map[id.item()])\n",
        "\n",
        "    return tag_predictions"
      ],
      "metadata": {
        "id": "xwZpST-YKyjP"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Peter Parker , the White House director of trade and manufacturing policy of U.S , said in an interview on Sunday morning that the White House was working to prepare for the possibility of a second wave of the coronavirus in the fall , though he said it wouldn ’t necessarily come\"\n",
        "\n",
        "predictions = predict(sentence, model, tokenize_sentences, idx_to_tags)\n",
        "\n",
        "print(f\"Sentence: {sentence}\")\n",
        "print(f\"Predicted labels: {predictions}\")\n",
        "\n",
        "for x,y in zip(sentence.split(' '), predictions):\n",
        "    if y != 'O':\n",
        "        print(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0Qra_9cOkYA",
        "outputId": "97f92cb0-0153-4471-9186-ddaa08ff8b44"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded sentence shape: torch.Size([1, 52])\n",
            "torch.Size([1, 52])\n",
            "torch.Size([1, 17, 52])\n",
            "Sentence: Peter Parker , the White House director of trade and manufacturing policy of U.S , said in an interview on Sunday morning that the White House was working to prepare for the possibility of a second wave of the coronavirus in the fall , though he said it wouldn ’t necessarily come\n",
            "Predicted labels: ['B-per', 'I-per', 'O', 'O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'I-tim', 'O', 'O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Peter B-per\n",
            "Parker I-per\n",
            "White B-org\n",
            "House I-org\n",
            "U.S B-org\n",
            "Sunday B-tim\n",
            "morning I-tim\n",
            "White B-org\n",
            "House I-org\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
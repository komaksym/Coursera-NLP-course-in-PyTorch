{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4HhgH9fVFjCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848d8baf-0dd6-4319-c88b-003c3f9b5187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Google drive setup\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/AttentionModelsCoursera/W1_NMT_Attention/W1/por-eng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JllT-5O9lu05",
        "outputId": "bb52f521-d3c2-4285-8d56-fa3b9c4473a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AttentionModelsCoursera/W1_NMT_Attention/W1/por-eng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import itertools\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from collections import Counter\n",
        "from utils import (sentences, train_dataset, val_dataset, train_loader, val_loader,\n",
        "                   tokenizer_eng, tokenizer_por, masked_loss, masked_acc, tokens_to_text)"
      ],
      "metadata": {
        "id": "7GLdPiE-GQNX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "OxlGeg_dRr5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences, portuguese_sentences = sentences\n",
        "\n",
        "print(f\"English (to translate) sentence:\\n\\n{english_sentences[-5]}\\n\")\n",
        "print(f\"Portuguese (translation) sentence:\\n\\n{portuguese_sentences[-5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKqu8oXERRRm",
        "outputId": "b1f6f2c6-d81e-4515-b267-dfe1fb4716eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English (to translate) sentence:\n",
            "\n",
            "No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\n",
            "\n",
            "Portuguese (translation) sentence:\n",
            "\n",
            "Não importa o quanto você tenta convencer os outros de que chocolate é baunilha, ele ainda será chocolate, mesmo que você possa convencer a si mesmo e poucos outros de que é baunilha.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del portuguese_sentences\n",
        "del english_sentences\n",
        "del sentences"
      ],
      "metadata": {
        "id": "P5_KmRiKmiAt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First 10 words of the english vocabulary:\\n\\n{sorted(tokenizer_eng.get_vocab().items(), key=lambda item: item[1])[:10]}\\n\")\n",
        "print(f\"First 10 words of the portuguese vocabulary:\\n\\n{sorted(tokenizer_por.get_vocab().items(), key=lambda item: item[1])[:10]}\")"
      ],
      "metadata": {
        "id": "xzQtQPDzlYOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb03efc4-3150-4cfa-f755-8d6f36dac1e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 words of the english vocabulary:\n",
            "\n",
            "[('[PAD]', 0), ('[UNK]', 1), ('[EOS]', 2), ('[SOS]', 3), ('.', 4), ('tom', 5), ('i', 6), ('to', 7), ('you', 8), ('the', 9)]\n",
            "\n",
            "First 10 words of the portuguese vocabulary:\n",
            "\n",
            "[('[PAD]', 0), ('[UNK]', 1), ('[EOS]', 2), ('[SOS]', 3), ('.', 4), ('tom', 5), ('que', 6), ('o', 7), ('nao', 8), ('eu', 9)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of the vocabulary\n",
        "vocab_size_por = tokenizer_eng.get_vocab_size()\n",
        "vocab_size_eng = tokenizer_eng.get_vocab_size()\n",
        "\n",
        "print(f\"Portuguese vocabulary is made up of {vocab_size_por} words\")\n",
        "print(f\"English vocabulary is made up of {vocab_size_eng} words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMMIOTCso5GG",
        "outputId": "b95cef14-2566-4025-c66d-d17334cc54b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portuguese vocabulary is made up of 12000 words\n",
            "English vocabulary is made up of 12000 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_to_id(token):\n",
        "    return tokenizer_por.token_to_id(token)\n",
        "\n",
        "\n",
        "def id_to_word(id):\n",
        "    return tokenizer_por.id_to_token(id)"
      ],
      "metadata": {
        "id": "-KnZE672xXqm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unk_id = word_to_id(\"[UNK]\")\n",
        "sos_id = word_to_id(\"[SOS]\")\n",
        "eos_id = word_to_id(\"[EOS]\")\n",
        "baunilha_id = word_to_id(\"baunilha\")\n",
        "\n",
        "print(f\"The id for the [UNK] token is {unk_id}\")\n",
        "print(f\"The id for the [SOS] token is {sos_id}\")\n",
        "print(f\"The id for the [EOS] token is {eos_id}\")\n",
        "print(f\"The id for baunilha (vanilla) is {baunilha_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFj-6OSuxYFG",
        "outputId": "0a2bba9a-f0a0-43b2-a46b-aeee8d9cd6a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The id for the [UNK] token is 1\n",
            "The id for the [SOS] token is 3\n",
            "The id for the [EOS] token is 2\n",
            "The id for baunilha (vanilla) is 5242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(to_translate, sr_translation), translation = next(iter(train_loader))\n",
        "\n",
        "print(f\"Tokenized english sentence:\\n{to_translate[0, :].numpy()}\\n\\n\")\n",
        "print(f\"Tokenized portuguese sentence (shifted to the right):\\n{sr_translation[0, :].numpy()}\\n\\n\")\n",
        "print(f\"Tokenized portuguese sentence:\\n{translation[0, :].numpy()}\\n\\n\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(f\"Len of Tokenized english sentence:\\n{len(to_translate[0, :].numpy())}\\n\\n\")\n",
        "print(f\"Len of Tokenized portuguese sentence (shifted to the right):\\n{len(sr_translation[0, :].numpy())}\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbLzXYW23nbW",
        "outputId": "446ce95b-45ad-4a24-e959-a929dcd9b276"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized english sentence:\n",
            "[   3  173   46   66  282   66   22 2167  793    4    2    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "\n",
            "\n",
            "Tokenized portuguese sentence (shifted to the right):\n",
            "[  3 103 171   6  12 744 378   4   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "\n",
            "\n",
            "Tokenized portuguese sentence:\n",
            "[103 171   6  12 744 378   4   2   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "\n",
            "\n",
            "\n",
            "Len of Tokenized english sentence:\n",
            "42\n",
            "\n",
            "\n",
            "Len of Tokenized portuguese sentence (shifted to the right):\n",
            "49\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(to_translate.size()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaNPlgXyNJxz",
        "outputId": "195bbccc-5313-49d5-955a-c1a8ea4acb18"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMT model with attention"
      ],
      "metadata": {
        "id": "R1vQncuf5WT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 12000\n",
        "UNITS = 256"
      ],
      "metadata": {
        "id": "3yrT4UUA5XWC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, units):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, units, padding_idx=0)\n",
        "        self.rnn = nn.LSTM(units, units, bidirectional=True, batch_first=True)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.rnn(x)\n",
        "        # Summarizing the bidirectional RNNs to follow the TF version\n",
        "        forward_output = x[:, :, :UNITS]\n",
        "        backward_output = x[:, :, UNITS:]\n",
        "        x = forward_output + backward_output\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "1Dwpp8_eBF76"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(VOCAB_SIZE, UNITS)\n",
        "\n",
        "encoder_output = encoder(to_translate)\n",
        "\n",
        "print(f'Tensor of sentences in english has shape: {to_translate.shape}\\n')\n",
        "print(f'Encoder output has shape: {encoder_output.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coZ1glxoJiRv",
        "outputId": "76481da1-a185-4551-ffde-961ce1395b30"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor of sentences in english has shape: torch.Size([64, 42])\n",
            "\n",
            "Encoder output has shape: torch.Size([64, 42, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Attention"
      ],
      "metadata": {
        "id": "SfI3vy3cUZ3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha = nn.MultiheadAttention(units, 1, batch_first=True)\n",
        "        self.layernorm = nn.LayerNorm(units)\n",
        "\n",
        "    def forward(self, context, target):\n",
        "        attn_output = self.mha(query=target,key=context, value=context)\n",
        "        x = target + attn_output[0]\n",
        "        x = self.layernorm(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "PkeZr7_vKe_w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "sr_translation_embed = nn.Embedding(VOCAB_SIZE, UNITS, 0)(sr_translation)\n",
        "\n",
        "attention_result = attention_layer(encoder_output, sr_translation_embed)\n",
        "\n",
        "print(f'Tensor of contexts has shape: {encoder_output.shape}')\n",
        "print(f'Tensor of translations has shape: {sr_translation_embed.shape}')\n",
        "print(f'Tensor of attention scores has shape: {attention_result.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2gsNK36XfgJ",
        "outputId": "9fa54d0e-0043-4e47-af1c-224a449a01d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor of contexts has shape: torch.Size([64, 42, 256])\n",
            "Tensor of translations has shape: torch.Size([64, 49, 256])\n",
            "Tensor of attention scores has shape: torch.Size([64, 49, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "4iuxMJx7cnB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, units):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, units, padding_idx=0)\n",
        "        self.pre_attention_rnn = nn.LSTM(units, units, batch_first=True)\n",
        "        self.attention = CrossAttention(units)\n",
        "        self.post_attention_rnn = nn.LSTM(units, units, batch_first=True)\n",
        "        self.output_layer = nn.Linear(units, vocab_size)\n",
        "        self.activation = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, context, target, state=None, return_state=False):\n",
        "        x = self.embedding(target)\n",
        "        x, (hidden_state, cell_state) = self.pre_attention_rnn(x, state)\n",
        "        x = self.attention(context, x)\n",
        "        x, _ = self.post_attention_rnn(x)\n",
        "        x = self.output_layer(x)\n",
        "        logits = self.activation(x)\n",
        "\n",
        "        if return_state:\n",
        "            return logits, [hidden_state, cell_state]\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "9uaq8tR4cnmj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(VOCAB_SIZE, UNITS)\n",
        "\n",
        "logits = decoder(encoder_output, sr_translation)\n",
        "\n",
        "print(f'Tensor of contexts has shape: {encoder_output.shape}')\n",
        "print(f'Tensor of right-shifted translations has shape: {sr_translation.shape}')\n",
        "print(f'Tensor of logits has shape: {logits.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMVYa392xyjW",
        "outputId": "13806a52-c2df-40e1-b6cd-c4773df0e74a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor of contexts has shape: torch.Size([64, 42, 256])\n",
            "Tensor of right-shifted translations has shape: torch.Size([64, 49])\n",
            "Tensor of logits has shape: torch.Size([64, 49, 12000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translator"
      ],
      "metadata": {
        "id": "GPOfZIPYBNNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "_sgfznSZWFvo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(nn.Module):\n",
        "    def __init__(self, vocab_size, units):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(vocab_size, units)\n",
        "        self.decoder = Decoder(vocab_size, units)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        context, targets = inputs\n",
        "\n",
        "        encoded_context = self.encoder(context)\n",
        "        logits = self.decoder(encoded_context, targets)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "ghu6C60J1jD_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(VOCAB_SIZE, UNITS).to(device)\n",
        "to_translate, sr_translation = to_translate.to(device), sr_translation.to(device)\n",
        "\n",
        "logits = translator((to_translate, sr_translation))\n",
        "\n",
        "print(f'Tensor of sentences to translate has shape: {to_translate.shape}')\n",
        "print(f'Tensor of right-shifted translations has shape: {sr_translation.shape}')\n",
        "print(f'Tensor of logits has shape: {logits.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxw4GurPGfsh",
        "outputId": "999e847f-11b6-4dc5-edf6-d8bf8c9c10d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor of sentences to translate has shape: torch.Size([64, 42])\n",
            "Tensor of right-shifted translations has shape: torch.Size([64, 49])\n",
            "Tensor of logits has shape: torch.Size([64, 49, 12000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=translator.parameters())\n",
        "criterion = masked_loss\n",
        "acc = masked_acc"
      ],
      "metadata": {
        "id": "Kysqf7SpPg0B"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "H9sDgrl3HGvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 20\n",
        "STEPS_PER_EPOCH = 500\n",
        "patience = 3\n",
        "min_loss = float('inf')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Mini batch loss\n",
        "    running_loss = 0.0\n",
        "    # Epoch loss for early stopping\n",
        "    epoch_loss = 0.0\n",
        "    translator.train()\n",
        "\n",
        "    # Using itertools for fixed length iteration over non subscriptable DataLoader\n",
        "    for i, data in enumerate(itertools.islice(train_loader,  STEPS_PER_EPOCH)):\n",
        "        (context, target_in), target_out = data\n",
        "\n",
        "        context, target_in, target_out = context.to(device), target_in.to(device), target_out.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = translator((context, target_in))\n",
        "        accuracy = acc(target_out, outputs)\n",
        "        loss = criterion(target_out, outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        #Getting the loss of the epoch\n",
        "        if i+1 == STEPS_PER_EPOCH:\n",
        "            epoch_loss = running_loss\n",
        "\n",
        "        if i % 100 == 99:\n",
        "            print(f\"\\n[epoch: {epoch+1}, mini batch: {i+1}] loss: {running_loss:.4f}, accuracy: {accuracy:.4f}\\n\")\n",
        "            running_loss = 0\n",
        "\n",
        "    # Update the best loss if it's better than the previous one\n",
        "    if epoch_loss < min_loss:\n",
        "        min_loss = epoch_loss\n",
        "        patience = 3\n",
        "\n",
        "    else:\n",
        "        # Losing patience\n",
        "        patience -= 1\n",
        "\n",
        "        if patience == 0:\n",
        "            break"
      ],
      "metadata": {
        "id": "FUYcGoGOHHVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "amoHG9_Q1Iyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 3\n",
        "min_loss = float('inf')\n",
        "\n",
        "running_loss = 0.0\n",
        "translator.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(itertools.islice(val_loader,  STEPS_PER_EPOCH)):\n",
        "        (context, target_in), target_out = data\n",
        "\n",
        "        context, target_in, target_out = context.to(device), target_in.to(device), target_out.to(device)\n",
        "\n",
        "        outputs = translator((context, target_in))\n",
        "        loss = criterion(target_out, outputs)\n",
        "        accuracy = acc(target_out, outputs)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 100 == 99:\n",
        "            print(f\"\\n[mini batch: {i+1}] validation loss: {running_loss:.4f}, validation accuracy: {accuracy:.4f}\\n\")\n",
        "            running_loss = 0"
      ],
      "metadata": {
        "id": "IMqkbJz31JuS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9617371,"sourceType":"datasetVersion","datasetId":5754974}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"cd /kaggle/input/dataset-eng-por","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:45:44.143759Z","iopub.execute_input":"2024-10-14T12:45:44.144115Z","iopub.status.idle":"2024-10-14T12:45:44.156904Z","shell.execute_reply.started":"2024-10-14T12:45:44.144069Z","shell.execute_reply":"2024-10-14T12:45:44.155977Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset-eng-por\n","output_type":"stream"}]},{"cell_type":"code","source":"import pdb\nimport torch\nimport itertools\nimport numpy as np\nimport torch.nn as nn\nfrom collections import Counter\nfrom utils_PT import (sentences, train_dataset, val_dataset, train_loader, val_loader,\n                   tokenizer_eng, tokenizer_por, masked_loss, masked_acc, ids_to_text, encode_sample, pt_lower_and_split_punct)","metadata":{"id":"7GLdPiE-GQNX","execution":{"iopub.status.busy":"2024-10-14T12:45:44.161472Z","iopub.execute_input":"2024-10-14T12:45:44.162007Z","iopub.status.idle":"2024-10-14T12:45:59.063503Z","shell.execute_reply.started":"2024-10-14T12:45:44.161974Z","shell.execute_reply":"2024-10-14T12:45:59.062684Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"_sgfznSZWFvo","execution":{"iopub.status.busy":"2024-10-14T12:45:59.064986Z","iopub.execute_input":"2024-10-14T12:45:59.065384Z","iopub.status.idle":"2024-10-14T12:45:59.096977Z","shell.execute_reply.started":"2024-10-14T12:45:59.065351Z","shell.execute_reply":"2024-10-14T12:45:59.096111Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation","metadata":{"id":"OxlGeg_dRr5F"}},{"cell_type":"code","source":"english_sentences, portuguese_sentences = sentences\n\nprint(f\"English (to translate) sentence:\\n\\n{english_sentences[-5]}\\n\")\nprint(f\"Portuguese (translation) sentence:\\n\\n{portuguese_sentences[-5]}\")","metadata":{"id":"IKqu8oXERRRm","outputId":"dfa12300-c374-49ae-bea2-c9621abfc330","execution":{"iopub.status.busy":"2024-10-14T12:45:59.098066Z","iopub.execute_input":"2024-10-14T12:45:59.098361Z","iopub.status.idle":"2024-10-14T12:45:59.108975Z","shell.execute_reply.started":"2024-10-14T12:45:59.098328Z","shell.execute_reply":"2024-10-14T12:45:59.108113Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"English (to translate) sentence:\n\nNo matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\n\nPortuguese (translation) sentence:\n\nNão importa o quanto você tenta convencer os outros de que chocolate é baunilha, ele ainda será chocolate, mesmo que você possa convencer a si mesmo e poucos outros de que é baunilha.\n","output_type":"stream"}]},{"cell_type":"code","source":"source = pt_lower_and_split_punct(english_sentences[-5])\nprint(f\"source: {source}\\n\")\n\nencoded = tokenizer_eng.encode(source[0]).ids\nprint(f\"encoded: {encoded}\\n\")\nprint(f\"len(encoded): {len(encoded)}\")\n\ndecoded = tokenizer_eng.decode(encoded)\nprint(f\"decoded: {decoded}\\n\")\nprint(f\"len(decoded): {len(decoded)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:45:59.110971Z","iopub.execute_input":"2024-10-14T12:45:59.111283Z","iopub.status.idle":"2024-10-14T12:45:59.119057Z","shell.execute_reply.started":"2024-10-14T12:45:59.111252Z","shell.execute_reply":"2024-10-14T12:45:59.118189Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"source: ['[SOS] no matter how much you try to convince people that chocolate is vanilla ,  itll still be chocolate ,  even though you may manage to convince yourself and a few others that its vanilla . [EOS]']\n\nencoded: [3, 89, 473, 49, 106, 8, 220, 7, 1060, 135, 13, 1107, 12, 4151, 24, 502, 103, 33, 1107, 24, 251, 1169, 8, 219, 2558, 7, 1060, 344, 43, 11, 365, 791, 13, 52, 4151, 4, 2]\n\nlen(encoded): 37\ndecoded: [SOS] no matter how much you try to convince people that chocolate is vanilla , itll still be chocolate , even though you may manage to convince yourself and a few others that its vanilla . [EOS]\n\nlen(decoded): 195\n","output_type":"stream"}]},{"cell_type":"code","source":"del portuguese_sentences\ndel english_sentences\ndel sentences","metadata":{"id":"P5_KmRiKmiAt","execution":{"iopub.status.busy":"2024-10-14T12:45:59.119994Z","iopub.execute_input":"2024-10-14T12:45:59.120264Z","iopub.status.idle":"2024-10-14T12:45:59.127931Z","shell.execute_reply.started":"2024-10-14T12:45:59.120234Z","shell.execute_reply":"2024-10-14T12:45:59.127017Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"ten_words_eng_vocab = sorted(tokenizer_eng.get_vocab().items(), key=lambda item: item[1])[:10]\nten_words_por_vocab = sorted(tokenizer_por.get_vocab().items(), key=lambda item: item[1])[:10]\nprint(f\"First 10 words of the english vocabulary:\\n\\n{[token[0] for token in ten_words_eng_vocab]}\\n\")\nprint(f\"First 10 words of the portuguese vocabulary:\\n\\n{[token[0] for token in ten_words_por_vocab]}\")","metadata":{"id":"xzQtQPDzlYOH","outputId":"a5bf37d7-a341-4f8b-eecb-f0494f18edb7","execution":{"iopub.status.busy":"2024-10-14T12:45:59.128955Z","iopub.execute_input":"2024-10-14T12:45:59.129223Z","iopub.status.idle":"2024-10-14T12:45:59.188295Z","shell.execute_reply.started":"2024-10-14T12:45:59.129194Z","shell.execute_reply":"2024-10-14T12:45:59.187149Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"First 10 words of the english vocabulary:\n\n['[PAD]', '[UNK]', '[EOS]', '[SOS]', '.', 'tom', 'i', 'to', 'you', 'the']\n\nFirst 10 words of the portuguese vocabulary:\n\n['[PAD]', '[UNK]', '[EOS]', '[SOS]', '.', 'tom', 'que', 'o', 'nao', 'eu']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Size of the vocabulary\nvocab_size_por = tokenizer_eng.get_vocab_size()\nvocab_size_eng = tokenizer_eng.get_vocab_size()\n\nprint(f\"Portuguese vocabulary is made up of {vocab_size_por} words\")\nprint(f\"English vocabulary is made up of {vocab_size_eng} words\")","metadata":{"id":"VMMIOTCso5GG","outputId":"960224f9-8fd5-4d34-98bb-7565d2b0403f","execution":{"iopub.status.busy":"2024-10-14T12:45:59.189574Z","iopub.execute_input":"2024-10-14T12:45:59.189976Z","iopub.status.idle":"2024-10-14T12:45:59.198638Z","shell.execute_reply.started":"2024-10-14T12:45:59.189933Z","shell.execute_reply":"2024-10-14T12:45:59.197846Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Portuguese vocabulary is made up of 12000 words\nEnglish vocabulary is made up of 12000 words\n","output_type":"stream"}]},{"cell_type":"code","source":"def word_to_id(token):\n    return tokenizer_por.token_to_id(token)\n\n\ndef ids_to_words(id):\n    return tokenizer_por.id_to_token(id)","metadata":{"id":"-KnZE672xXqm","execution":{"iopub.status.busy":"2024-10-14T12:45:59.199939Z","iopub.execute_input":"2024-10-14T12:45:59.200236Z","iopub.status.idle":"2024-10-14T12:45:59.206603Z","shell.execute_reply.started":"2024-10-14T12:45:59.200205Z","shell.execute_reply":"2024-10-14T12:45:59.205858Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"unk_id = word_to_id(\"[UNK]\")\nsos_id = word_to_id(\"[SOS]\")\neos_id = word_to_id(\"[EOS]\")\nbaunilha_id = word_to_id(\"baunilha\")\n\nprint(f\"The id for the [UNK] token is {unk_id}\")\nprint(f\"The id for the [SOS] token is {sos_id}\")\nprint(f\"The id for the [EOS] token is {eos_id}\")\nprint(f\"The id for baunilha (vanilla) is {baunilha_id}\")","metadata":{"id":"UFj-6OSuxYFG","outputId":"68606c95-da88-4c5d-946a-08ae17eba943","execution":{"iopub.status.busy":"2024-10-14T12:45:59.207727Z","iopub.execute_input":"2024-10-14T12:45:59.208053Z","iopub.status.idle":"2024-10-14T12:45:59.217434Z","shell.execute_reply.started":"2024-10-14T12:45:59.208022Z","shell.execute_reply":"2024-10-14T12:45:59.216562Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"The id for the [UNK] token is 1\nThe id for the [SOS] token is 3\nThe id for the [EOS] token is 2\nThe id for baunilha (vanilla) is 5242\n","output_type":"stream"}]},{"cell_type":"code","source":"(to_translate, sr_translation), translation = next(iter(train_loader))\n\nprint(f\"Tokenized english sentence:\\n{to_translate[0, :].numpy()}\\n\\n\")\nprint(f\"Tokenized portuguese sentence (shifted to the right):\\n{sr_translation[0, :].numpy()}\\n\\n\")\nprint(f\"Tokenized portuguese sentence:\\n{translation[0, :].numpy()}\\n\\n\")\n\nprint(tokenizer_eng.decode(to_translate[0, :].numpy()))\nprint(tokenizer_por.decode(sr_translation[0, :].numpy()))\nprint(tokenizer_por.decode(translation[0, :].numpy()))","metadata":{"id":"HbLzXYW23nbW","outputId":"95723009-c945-4b36-98db-7851be5bf8ed","execution":{"iopub.status.busy":"2024-10-14T12:45:59.221561Z","iopub.execute_input":"2024-10-14T12:45:59.221919Z","iopub.status.idle":"2024-10-14T12:45:59.301720Z","shell.execute_reply.started":"2024-10-14T12:45:59.221888Z","shell.execute_reply":"2024-10-14T12:45:59.300821Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Tokenized english sentence:\n[   3  173   46   66  282   66   22 2167  793    4    2    0    0    0\n    0    0    0    0    0]\n\n\nTokenized portuguese sentence (shifted to the right):\n[  3 103 171   6  12 744 378   4   0   0   0   0   0   0   0   0   0   0\n   0]\n\n\nTokenized portuguese sentence:\n[103 171   6  12 744 378   4   2   0   0   0   0   0   0   0   0   0   0\n   0]\n\n\n[SOS] lets go as soon as it stops raining . [EOS]\n[SOS] vamos assim que a chuva parar .\nvamos assim que a chuva parar . [EOS]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Encoder","metadata":{"id":"R1vQncuf5WT1"}},{"cell_type":"code","source":"VOCAB_SIZE = 12000\nUNITS = 256","metadata":{"id":"3yrT4UUA5XWC","execution":{"iopub.status.busy":"2024-10-14T12:45:59.302900Z","iopub.execute_input":"2024-10-14T12:45:59.303205Z","iopub.status.idle":"2024-10-14T12:45:59.306863Z","shell.execute_reply.started":"2024-10-14T12:45:59.303171Z","shell.execute_reply":"2024-10-14T12:45:59.306067Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, vocab_size, units):\n        super().__init__()\n\n        self.embedding = nn.Embedding(vocab_size, units, padding_idx=0)\n        self.rnn = nn.LSTM(units, units, bidirectional=True, batch_first=True)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x, _ = self.rnn(x)\n        # Summarizing the bidirectional RNNs to follow the TF version\n        forward_output = x[:, :, :UNITS]\n        backward_output = x[:, :, UNITS:]\n        x = forward_output + backward_output\n\n        return x","metadata":{"id":"1Dwpp8_eBF76","execution":{"iopub.status.busy":"2024-10-14T12:45:59.307770Z","iopub.execute_input":"2024-10-14T12:45:59.308065Z","iopub.status.idle":"2024-10-14T12:45:59.317904Z","shell.execute_reply.started":"2024-10-14T12:45:59.308032Z","shell.execute_reply":"2024-10-14T12:45:59.317019Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(VOCAB_SIZE, UNITS)\n\nencoder_output = encoder(to_translate)\n\nprint(f'Tensor of sentences in english has shape: {to_translate.shape}\\n')\nprint(f'Encoder output has shape: {encoder_output.shape}')","metadata":{"id":"coZ1glxoJiRv","outputId":"19e6e093-1d60-4dc2-9db4-a7f1533b4439","execution":{"iopub.status.busy":"2024-10-14T12:45:59.319462Z","iopub.execute_input":"2024-10-14T12:45:59.319895Z","iopub.status.idle":"2024-10-14T12:45:59.522996Z","shell.execute_reply.started":"2024-10-14T12:45:59.319853Z","shell.execute_reply":"2024-10-14T12:45:59.522023Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Tensor of sentences in english has shape: torch.Size([64, 19])\n\nEncoder output has shape: torch.Size([64, 19, 256])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Cross Attention","metadata":{"id":"SfI3vy3cUZ3Q"}},{"cell_type":"code","source":"class CrossAttention(nn.Module):\n    def __init__(self, units):\n        super().__init__()\n\n        self.mha = nn.MultiheadAttention(units, 1, batch_first=True)\n        self.layernorm = nn.LayerNorm(units)\n\n    def forward(self, context, target):\n        attn_output = self.mha(query=target,key=context, value=context)\n        x = target + attn_output[0] # [0] because we only need the attention output and no weights\n        x = self.layernorm(x) \n\n        return x","metadata":{"id":"PkeZr7_vKe_w","execution":{"iopub.status.busy":"2024-10-14T12:45:59.524263Z","iopub.execute_input":"2024-10-14T12:45:59.524650Z","iopub.status.idle":"2024-10-14T12:45:59.531478Z","shell.execute_reply.started":"2024-10-14T12:45:59.524601Z","shell.execute_reply":"2024-10-14T12:45:59.530395Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"attention_layer = CrossAttention(UNITS)\n\nsr_translation_embed = nn.Embedding(VOCAB_SIZE, UNITS, 0)(sr_translation)\n\nattention_result = attention_layer(encoder_output, sr_translation_embed)\n\nprint(f'Tensor of contexts has shape: {encoder_output.shape}')\nprint(f'Tensor of translations has shape: {sr_translation_embed.shape}')\nprint(f'Tensor of attention scores has shape: {attention_result.shape}')","metadata":{"id":"-2gsNK36XfgJ","outputId":"0ef58385-ab82-4eda-cce7-cc59612aaa7e","execution":{"iopub.status.busy":"2024-10-14T12:45:59.533118Z","iopub.execute_input":"2024-10-14T12:45:59.533517Z","iopub.status.idle":"2024-10-14T12:45:59.658510Z","shell.execute_reply.started":"2024-10-14T12:45:59.533476Z","shell.execute_reply":"2024-10-14T12:45:59.657515Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Tensor of contexts has shape: torch.Size([64, 19, 256])\nTensor of translations has shape: torch.Size([64, 19, 256])\nTensor of attention scores has shape: torch.Size([64, 19, 256])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Decoder","metadata":{"id":"4iuxMJx7cnB4"}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, vocab_size, units):\n        super().__init__()\n\n        self.embedding = nn.Embedding(vocab_size, units, padding_idx=0)\n        self.pre_attention_rnn = nn.LSTM(units, units, batch_first=True)\n        self.attention = CrossAttention(units)\n        self.post_attention_rnn = nn.LSTM(units, units, batch_first=True)\n        self.output_layer = nn.Linear(units, vocab_size)\n        self.activation = nn.LogSoftmax(dim=-1)\n\n    def forward(self, context, target_in, state=None, return_state=False):\n        x = self.embedding(target_in)\n        x, (hidden_state, cell_state) = self.pre_attention_rnn(x, state)\n        x = self.attention(context, x)\n        x, _ = self.post_attention_rnn(x)\n        x = self.output_layer(x)\n        logits = self.activation(x)\n\n        if return_state:\n            return logits, [hidden_state, cell_state]\n\n        return logits","metadata":{"id":"9uaq8tR4cnmj","execution":{"iopub.status.busy":"2024-10-14T12:45:59.659764Z","iopub.execute_input":"2024-10-14T12:45:59.660155Z","iopub.status.idle":"2024-10-14T12:45:59.668582Z","shell.execute_reply.started":"2024-10-14T12:45:59.660119Z","shell.execute_reply":"2024-10-14T12:45:59.667659Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"decoder = Decoder(VOCAB_SIZE, UNITS)\n\nlogits = decoder(encoder_output, sr_translation)\n\nprint(f'Tensor of contexts has shape: {encoder_output.shape}')\nprint(f'Tensor of right-shifted translations has shape: {sr_translation.shape}')\nprint(f'Tensor of logits has shape: {logits.shape}')","metadata":{"id":"GMVYa392xyjW","outputId":"e62da169-facb-4967-bb52-93987b6c368c","execution":{"iopub.status.busy":"2024-10-14T12:45:59.669884Z","iopub.execute_input":"2024-10-14T12:45:59.670236Z","iopub.status.idle":"2024-10-14T12:45:59.860700Z","shell.execute_reply.started":"2024-10-14T12:45:59.670196Z","shell.execute_reply":"2024-10-14T12:45:59.859733Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Tensor of contexts has shape: torch.Size([64, 19, 256])\nTensor of right-shifted translations has shape: torch.Size([64, 19])\nTensor of logits has shape: torch.Size([64, 19, 12000])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Translator","metadata":{"id":"GPOfZIPYBNNu"}},{"cell_type":"code","source":"class Translator(nn.Module):\n    def __init__(self, vocab_size, units):\n        super().__init__()\n\n        self.encoder = Encoder(vocab_size, units)\n        self.decoder = Decoder(vocab_size, units)\n\n    def forward(self, inputs):\n        context, targets = inputs\n\n        encoded_context = self.encoder(context)\n        logits = self.decoder(encoded_context, targets)\n\n        return logits","metadata":{"id":"ghu6C60J1jD_","execution":{"iopub.status.busy":"2024-10-14T12:45:59.862016Z","iopub.execute_input":"2024-10-14T12:45:59.862481Z","iopub.status.idle":"2024-10-14T12:45:59.868777Z","shell.execute_reply.started":"2024-10-14T12:45:59.862436Z","shell.execute_reply":"2024-10-14T12:45:59.867681Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"translator = Translator(VOCAB_SIZE, UNITS).to(device)\n\n# Loading the model\n#translator.load_state_dict(torch.load('/kaggle/working/model_weights.pth', map_location=torch.device(device), weights_only=True))\n\nlogits = translator((to_translate.to(device), sr_translation.to(device)))\n\nprint(f'Tensor of sentences to translate has shape: {to_translate.shape}')\nprint(f'Tensor of right-shifted translations has shape: {sr_translation.shape}')\nprint(f'Tensor of logits has shape: {logits.shape}')","metadata":{"id":"Hxw4GurPGfsh","outputId":"f527ed49-df4c-418a-a921-3d7e6feb27d2","execution":{"iopub.status.busy":"2024-10-14T12:45:59.870063Z","iopub.execute_input":"2024-10-14T12:45:59.870413Z","iopub.status.idle":"2024-10-14T12:46:00.544994Z","shell.execute_reply.started":"2024-10-14T12:45:59.870362Z","shell.execute_reply":"2024-10-14T12:46:00.544091Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Tensor of sentences to translate has shape: torch.Size([64, 19])\nTensor of right-shifted translations has shape: torch.Size([64, 19])\nTensor of logits has shape: torch.Size([64, 19, 12000])\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(params=translator.parameters())\ncriterion = masked_loss\nacc = masked_acc","metadata":{"id":"Kysqf7SpPg0B","execution":{"iopub.status.busy":"2024-10-14T12:46:00.545986Z","iopub.execute_input":"2024-10-14T12:46:00.546255Z","iopub.status.idle":"2024-10-14T12:46:01.362746Z","shell.execute_reply.started":"2024-10-14T12:46:00.546225Z","shell.execute_reply":"2024-10-14T12:46:01.361861Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"H9sDgrl3HGvD"}},{"cell_type":"code","source":"NUM_EPOCHS = 20\nSTEPS_PER_EPOCH = 500\nVALIDATION_STEPS = 50\npatience = 3\nbest_loss = float('inf')\nnum_batches_train = len(train_loader)\nnum_batches_val = len(val_loader)\n\n\nfor epoch in range(NUM_EPOCHS):\n    translator.train()\n    \n    # Mini batch loss\n    running_loss_train = 0.0\n    running_accuracy_train = 0.0\n    running_loss_val = 0.0\n    running_accuracy_val = 0.0\n    \n    # Using itertools for fixed length iteration over non subscriptable DataLoader\n    for i, data in enumerate(itertools.islice(train_loader,  STEPS_PER_EPOCH)):\n        (context, target_in), target_out = data\n        context, target_in, target_out = context.to(device), target_in.to(device), target_out.to(device)\n        \n        optimizer.zero_grad()\n        outputs = translator((context, target_in))\n        loss = criterion(target_out, outputs)\n        accuracy = acc(target_out, outputs)\n        loss.backward()\n        optimizer.step()\n\n        running_loss_train += loss.item()\n        running_accuracy_train = accuracy \n        \n    \n    # Validation\n    translator.eval()\n    with torch.no_grad():\n        for i, data in enumerate(itertools.islice(val_loader,  VALIDATION_STEPS)):\n            (context, target_in), target_out = data\n            context, target_in, target_out = context.to(device), target_in.to(device), target_out.to(device)\n\n            outputs = translator((context, target_in))\n            loss = criterion(target_out, outputs)\n            accuracy = acc(target_out, outputs)\n\n            running_loss_val += loss.item()\n            running_accuracy_val = accuracy \n            \n            \n    # Print the data\n    print(f\"\\n[epoch: {epoch+1}/{NUM_EPOCHS}] masked_loss: {(running_loss_train / num_batches_train):.4f}, masked_acc: {running_accuracy_train:.4f}, val_masked_loss: {(running_loss_val / num_batches_val):.4f}, val_masked_acc: {running_accuracy_val:.4f}\\n\")\n    \n    # Update the best loss if it's better than the previous one\n    if running_loss_train < best_loss:\n        best_loss = running_loss_train\n        patience = 3\n\n    else:\n        # Losing patience\n        patience -= 1\n\n        if patience == 0:\n            print(\"Early stopping was triggered\")","metadata":{"id":"FUYcGoGOHHVS","_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-10-14T12:46:01.363872Z","iopub.execute_input":"2024-10-14T12:46:01.364266Z","iopub.status.idle":"2024-10-14T12:46:01.374180Z","shell.execute_reply.started":"2024-10-14T12:46:01.364233Z","shell.execute_reply":"2024-10-14T12:46:01.373265Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'NUM_EPOCHS = 20\\nSTEPS_PER_EPOCH = 500\\nVALIDATION_STEPS = 50\\npatience = 3\\nbest_loss = float(\\'inf\\')\\nnum_batches_train = len(train_loader)\\nnum_batches_val = len(val_loader)\\n\\n\\nfor epoch in range(NUM_EPOCHS):\\n    translator.train()\\n    \\n    # Mini batch loss\\n    running_loss_train = 0.0\\n    running_accuracy_train = 0.0\\n    running_loss_val = 0.0\\n    running_accuracy_val = 0.0\\n    \\n    # Using itertools for fixed length iteration over non subscriptable DataLoader\\n    for i, data in enumerate(itertools.islice(train_loader,  STEPS_PER_EPOCH)):\\n        (context, target_in), target_out = data\\n        context, target_in, target_out = context.to(device), target_in.to(device), target_out.to(device)\\n        \\n        optimizer.zero_grad()\\n        outputs = translator((context, target_in))\\n        loss = criterion(target_out, outputs)\\n        accuracy = acc(target_out, outputs)\\n        loss.backward()\\n        optimizer.step()\\n\\n        running_loss_train += loss.item()\\n        running_accuracy_train = accuracy \\n        \\n    \\n    # Validation\\n    translator.eval()\\n    with torch.no_grad():\\n        for i, data in enumerate(itertools.islice(val_loader,  VALIDATION_STEPS)):\\n            (context, target_in), target_out = data\\n            context, target_in, target_out = context.to(device), target_in.to(device), target_out.to(device)\\n\\n            outputs = translator((context, target_in))\\n            loss = criterion(target_out, outputs)\\n            accuracy = acc(target_out, outputs)\\n\\n            running_loss_val += loss.item()\\n            running_accuracy_val = accuracy \\n            \\n            \\n    # Print the data\\n    print(f\"\\n[epoch: {epoch+1}/{NUM_EPOCHS}] masked_loss: {(running_loss_train / num_batches_train):.4f}, masked_acc: {running_accuracy_train:.4f}, val_masked_loss: {(running_loss_val / num_batches_val):.4f}, val_masked_acc: {running_accuracy_val:.4f}\\n\")\\n    \\n    # Update the best loss if it\\'s better than the previous one\\n    if running_loss_train < best_loss:\\n        best_loss = running_loss_train\\n        patience = 3\\n\\n    else:\\n        # Losing patience\\n        patience -= 1\\n\\n        if patience == 0:\\n            print(\"Early stopping was triggered\")'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Using the model for inference","metadata":{"id":"Nat9JkDJT8Tg"}},{"cell_type":"code","source":"def generate_next_token(context, decoder, next_token, state, done, temperature=0.0):\n    logits, state = decoder(context, next_token, state, return_state=True)\n    logits = logits[:, -1, :]\n\n    if temperature == 0.0:\n        next_token = torch.argmax(logits, dim=-1)\n\n    else:\n        logits /= temperature\n        distribution = torch.distributions.categorical.Categorical(logits=logits)\n        next_token = distribution.sample()\n\n    logits = torch.squeeze(logits)\n\n    next_token = torch.squeeze(next_token)\n\n    logit = logits[next_token].detach().numpy()\n\n    next_token = torch.reshape(next_token, shape=(1,1))\n    if next_token == eos_id:\n        done = True\n\n    return next_token, logit, state, done","metadata":{"id":"dRVu0cp0T9vu","execution":{"iopub.status.busy":"2024-10-14T12:46:01.423609Z","iopub.execute_input":"2024-10-14T12:46:01.423921Z","iopub.status.idle":"2024-10-14T12:46:01.431402Z","shell.execute_reply.started":"2024-10-14T12:46:01.423889Z","shell.execute_reply":"2024-10-14T12:46:01.430431Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"eng_sentence = \"I love languages\"\n\ncontext = torch.tensor(encode_sample(eng_sentence))\ncontext = torch.unsqueeze(context, dim=0)\ncontext = encoder(context)\n\nnext_token = torch.full((1,1), sos_id)\n\nstate = [torch.rand((1, 1, UNITS)), torch.rand((1, 1, UNITS))]\ndone = False\n\nnext_token, logit, state, done = generate_next_token(context, decoder, next_token, state, done, temperature=0.5)\nprint(f\"Next token: {next_token}\\nLogit: {logit:.4f}\\nDone? {done}\")\nnext_token = next_token.tolist()","metadata":{"id":"E8UgIJZjD2_F","outputId":"0dc50d58-86b6-4f66-d31b-18051fd7f060","execution":{"iopub.status.busy":"2024-10-14T12:46:01.432690Z","iopub.execute_input":"2024-10-14T12:46:01.433074Z","iopub.status.idle":"2024-10-14T12:46:01.499576Z","shell.execute_reply.started":"2024-10-14T12:46:01.433006Z","shell.execute_reply":"2024-10-14T12:46:01.498621Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Next token: tensor([[8541]])\nLogit: -18.7596\nDone? False\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Translate","metadata":{"id":"CDG_-BNy-knN"}},{"cell_type":"code","source":"def translate(model, text, max_length=50, temperature=0.0):\n    model.eval()\n    with torch.no_grad():\n        tokens, logits = [], []\n\n        pre_text = text\n        text = torch.tensor(encode_sample(pre_text))[None, :]\n        context = model.encoder(text)\n\n        next_token = torch.full((1,1), sos_id)\n\n        state = [torch.zeros((1, 1, UNITS)), torch.zeros((1, 1, UNITS))]\n\n        done = False\n        for iteration in range(max_length):\n            try:\n                next_token, logit, state, done = generate_next_token(\n                    context=context,\n                    decoder=model.decoder,\n                    next_token=next_token,\n                    state=state,\n                    done=done,\n                    temperature=temperature\n                )\n            except:\n                raise Exception(\"Problem generating the next token\")\n\n            if done:\n                break\n\n            tokens.append(next_token)\n\n            logits.append(logit)\n\n        tokens = torch.cat(tokens, dim=-1).tolist()\n    \n    translation = ids_to_text(tokens, tokenizer_por)\n\n    return translation, logits[-1], tokens","metadata":{"id":"ZLqbKnLaxZ6J","execution":{"iopub.status.busy":"2024-10-14T12:46:01.500777Z","iopub.execute_input":"2024-10-14T12:46:01.501107Z","iopub.status.idle":"2024-10-14T12:46:01.510948Z","shell.execute_reply.started":"2024-10-14T12:46:01.501071Z","shell.execute_reply":"2024-10-14T12:46:01.510004Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Running this cell multiple times should return the same output since temp is 0\n\ntemp = 0.0\noriginal_sentence = \"I love languages\"\n\ntranslation, logit, tokens = translate(translator.to(\"cpu\"), original_sentence, temperature=temp)\n\nprint(f\"Temperature: {temp}\\n\\nOriginal sentence: {original_sentence}\\nTranslation: {translation}\\nTranslation tokens:{tokens}\\nLogit: {logit:.3f}\")","metadata":{"id":"dBKxYvlcjX-F","outputId":"8d5b1254-4c3f-40c1-8c56-0cace5a4282d","execution":{"iopub.status.busy":"2024-10-14T12:51:14.155053Z","iopub.execute_input":"2024-10-14T12:51:14.155764Z","iopub.status.idle":"2024-10-14T12:51:14.183536Z","shell.execute_reply.started":"2024-10-14T12:51:14.155725Z","shell.execute_reply":"2024-10-14T12:51:14.182555Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Temperature: 0.0\n\nOriginal sentence: I love languages\nTranslation: ['eu adoro idiomas com as linguas']\nTranslation tokens:[[9, 537, 888, 20, 38, 1041]]\nLogit: -0.133\n","output_type":"stream"}]},{"cell_type":"code","source":"# Running this cell multiple times should return different outputs since temp is not 0\n# You can try different temperatures\n\ntemp = 0.7\noriginal_sentence = \"I love languages\"\n\ntranslation, logit, tokens = translate(translator.to(\"cpu\"), original_sentence, temperature=temp)\n\nprint(f\"Temperature: {temp}\\n\\nOriginal sentence: {original_sentence}\\nTranslation: {translation}\\nTranslation tokens:{tokens}\\nLogit: {logit:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:51:56.781674Z","iopub.execute_input":"2024-10-14T12:51:56.782578Z","iopub.status.idle":"2024-10-14T12:51:56.806715Z","shell.execute_reply.started":"2024-10-14T12:51:56.782537Z","shell.execute_reply":"2024-10-14T12:51:56.805738Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Temperature: 0.7\n\nOriginal sentence: I love languages\nTranslation: ['eu adoro linguas']\nTranslation tokens:[[9, 537, 1041]]\nLogit: -1.651\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Minimum Bayes-Risk Decoding","metadata":{}},{"cell_type":"code","source":"def generate_samples(model, text, n_samples=4, temperature=0.6):\n    samples, log_probs = [], []\n    \n    for _ in range(n_samples):\n        _, log_prob, sample = translate(model, text, temperature=temperature)\n        \n        samples.append(sample)\n        \n        log_probs.append(log_prob)\n        \n    return samples, log_probs","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:06.661434Z","iopub.execute_input":"2024-10-14T12:52:06.662153Z","iopub.status.idle":"2024-10-14T12:52:06.667631Z","shell.execute_reply.started":"2024-10-14T12:52:06.662113Z","shell.execute_reply":"2024-10-14T12:52:06.666662Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"samples, log_probs = generate_samples(translator, 'I love languages')\n\nfor s, l in zip(samples, log_probs):\n    print(f\"Translated tensor: {s} has logit: {l:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:06.669347Z","iopub.execute_input":"2024-10-14T12:52:06.669630Z","iopub.status.idle":"2024-10-14T12:52:06.986850Z","shell.execute_reply.started":"2024-10-14T12:52:06.669598Z","shell.execute_reply":"2024-10-14T12:52:06.985632Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Translated tensor: [[9, 537, 888, 1, 1759, 10120, 9, 9, 7007, 9, 3329, 537, 9, 9696, 9, 578, 9, 537, 1241, 9, 578, 9, 523, 9, 523, 9, 3680, 9, 523, 9, 7007, 9, 9, 523, 9, 523, 9, 537, 9, 523, 9, 9, 523, 9, 1410, 9, 578, 9, 1412, 9]] has logit: -0.665\nTranslated tensor: [[9, 537, 888, 543, 1041, 3624, 9, 9, 578, 9, 523, 9, 523, 9, 578, 9, 578, 9, 578, 9, 537, 9, 537, 9, 523, 9, 523, 9, 5584, 523, 9, 537, 9, 10490, 523, 9, 807, 9, 523, 9, 578, 9, 523, 9, 523, 9, 578, 9, 523, 9]] has logit: -1.263\nTranslated tensor: [[9, 537, 888, 166]] has logit: -5.841\nTranslated tensor: [[9, 537, 888, 4651, 12, 1041]] has logit: -4.314\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Comparing overlaps","metadata":{}},{"cell_type":"code","source":"def jaccard_similarity(candidate, reference):\n    \n    if (isinstance(candidate, list) and all(isinstance(i, list) for i in candidate)) and \\\n       (isinstance(reference, list) and all(isinstance(i, list) for i in reference)):\n        candidate_set = set(candidate[0])\n        reference_set = set(reference[0])\n\n    else:\n        candidate_set = set(candidate)\n        reference_set = set(reference)    \n    \n    common_tokens = candidate_set.intersection(reference_set)\n    \n    all_tokens = candidate_set.union(reference_set)\n    \n    overlap = len(common_tokens) / len(all_tokens)\n    \n    return overlap","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:06.988167Z","iopub.execute_input":"2024-10-14T12:52:06.988539Z","iopub.status.idle":"2024-10-14T12:52:06.995307Z","shell.execute_reply.started":"2024-10-14T12:52:06.988502Z","shell.execute_reply":"2024-10-14T12:52:06.994360Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"l1 = [1,2,3]\nl2 = [1,2,3,4]\n\njs = jaccard_similarity(l1, l2)\n\nprint(f\"jaccard similarity between lists: {l1} and {l2} is {js:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:06.996760Z","iopub.execute_input":"2024-10-14T12:52:06.997072Z","iopub.status.idle":"2024-10-14T12:52:07.005336Z","shell.execute_reply.started":"2024-10-14T12:52:06.997041Z","shell.execute_reply":"2024-10-14T12:52:07.004426Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"jaccard similarity between lists: [1, 2, 3] and [1, 2, 3, 4] is 0.750\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Rouge1 similarity","metadata":{}},{"cell_type":"code","source":"def rouge1_similarity(candidate, reference):\n    candidate_word_counts = Counter(candidate)\n    reference_word_counts = Counter(reference)    \n    \n    overlap = 0\n    \n    for token in candidate_word_counts.keys():\n        token_count_candidate = candidate_word_counts[token]\n        token_count_reference = reference_word_counts[token]        \n        \n        overlap += min(token_count_candidate, token_count_reference)\n        \n    precision = overlap / len(candidate)\n    \n    recall = overlap / len(reference)\n    \n    if precision + recall != 0:\n        f1_score = 2 * (precision * recall) / (precision + recall)\n        return f1_score\n    \n    return 0","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:07.008210Z","iopub.execute_input":"2024-10-14T12:52:07.009113Z","iopub.status.idle":"2024-10-14T12:52:07.017882Z","shell.execute_reply.started":"2024-10-14T12:52:07.009078Z","shell.execute_reply":"2024-10-14T12:52:07.017041Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"l1 = [0, 1]\nl2 = [5, 5, 7, 0, 232]\n\nr1s = rouge1_similarity(l1, l2)\n\nprint(f\"rouge 1 similarity between lists: {l1} and {l2} is {r1s:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:07.020817Z","iopub.execute_input":"2024-10-14T12:52:07.021102Z","iopub.status.idle":"2024-10-14T12:52:07.029765Z","shell.execute_reply.started":"2024-10-14T12:52:07.021071Z","shell.execute_reply":"2024-10-14T12:52:07.028918Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"rouge 1 similarity between lists: [0, 1] and [5, 5, 7, 0, 232] is 0.286\n","output_type":"stream"}]},{"cell_type":"code","source":"l1 = [1, 2, 3]\nl2 = [1, 2, 3, 4]\n\nr1s = rouge1_similarity(l1, l2)\n\nprint(f\"rouge 1 similarity between lists: {l1} and {l2} is {r1s:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:07.031178Z","iopub.execute_input":"2024-10-14T12:52:07.031534Z","iopub.status.idle":"2024-10-14T12:52:07.037473Z","shell.execute_reply.started":"2024-10-14T12:52:07.031492Z","shell.execute_reply":"2024-10-14T12:52:07.036583Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"rouge 1 similarity between lists: [1, 2, 3] and [1, 2, 3, 4] is 0.857\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Computing the overall score","metadata":{}},{"cell_type":"markdown","source":"# Average overlap","metadata":{}},{"cell_type":"code","source":"def average_overlap(samples, similarity_fn):\n    \n    scores = {}\n    \n    for index_candidate, candidate in enumerate(samples):\n        overlap = 0\n        \n        for index_sample, sample in enumerate(samples):\n            \n            if index_candidate == index_sample:\n                continue\n                \n            overlap += similarity_fn(candidate, sample)\n            \n        score = overlap / (len(samples) - 1)\n        \n        score = round(score, 3)\n        \n        scores[index_candidate] = score\n        \n    return scores","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:07.038752Z","iopub.execute_input":"2024-10-14T12:52:07.039112Z","iopub.status.idle":"2024-10-14T12:52:07.046687Z","shell.execute_reply.started":"2024-10-14T12:52:07.039072Z","shell.execute_reply":"2024-10-14T12:52:07.045931Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# Test with Jaccard similarity\n\nl1 = [1, 2, 3]\nl2 = [1, 2, 4]\nl3 = [1, 2, 4, 5]\n\navg_ovlp = average_overlap([l1, l2, l3], jaccard_similarity)\n\nprint(f\"average overlap between lists: {l1}, {l2} and {l3} using Jaccard similarity is:\\n\\n{avg_ovlp}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:07.047786Z","iopub.execute_input":"2024-10-14T12:52:07.048109Z","iopub.status.idle":"2024-10-14T12:52:07.057369Z","shell.execute_reply.started":"2024-10-14T12:52:07.048060Z","shell.execute_reply":"2024-10-14T12:52:07.056526Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"average overlap between lists: [1, 2, 3], [1, 2, 4] and [1, 2, 4, 5] using Jaccard similarity is:\n\n{0: 0.45, 1: 0.625, 2: 0.575}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test with Rouge1 similarity\n\nl1 = [1, 2, 3]\nl2 = [1, 4]\nl3 = [1, 2, 4, 5]\nl4 = [5,6]\n\navg_ovlp = average_overlap([l1, l2, l3, l4], rouge1_similarity)\n\nprint(f\"average overlap between lists: {l1}, {l2}, {l3} and {l4} using Rouge1 similarity is:\\n\\n{avg_ovlp}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:07.058688Z","iopub.execute_input":"2024-10-14T12:52:07.059167Z","iopub.status.idle":"2024-10-14T12:52:07.068153Z","shell.execute_reply.started":"2024-10-14T12:52:07.059126Z","shell.execute_reply":"2024-10-14T12:52:07.067275Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"average overlap between lists: [1, 2, 3], [1, 4], [1, 2, 4, 5] and [5, 6] using Rouge1 similarity is:\n\n{0: 0.324, 1: 0.356, 2: 0.524, 3: 0.111}\n","output_type":"stream"}]},{"cell_type":"code","source":"def weighted_avg_overlap(samples, log_probs, similarity_fn):\n    scores = {}\n    \n    for index_candidate, candidate in enumerate(samples):\n        overlap, weighted_sum = 0.0, 0.0\n        \n        for index_sample, (sample, logprob) in enumerate(zip(samples, log_probs)):\n            if index_candidate == index_sample:\n                continue\n                \n            sample_prob = float(np.exp(logprob))\n            weighted_sum += sample_prob\n            \n            sample_overlap = similarity_fn(candidate, sample)\n            overlap += sample_overlap * sample_prob\n            \n        score = overlap / weighted_sum\n        score = round(score, 3)\n        \n        scores[index_candidate] = score\n        \n    return scores","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:07.069210Z","iopub.execute_input":"2024-10-14T12:52:07.069544Z","iopub.status.idle":"2024-10-14T12:52:07.081405Z","shell.execute_reply.started":"2024-10-14T12:52:07.069511Z","shell.execute_reply":"2024-10-14T12:52:07.080542Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"l1 = [1, 2, 3]\nl2 = [1, 2, 4]\nl3 = [1, 2, 4, 5]\nlog_probs = [0.4, 0.2, 0.5]\n\nw_avg_ovlp = weighted_avg_overlap([l1, l2, l3], log_probs, jaccard_similarity)\n\nprint(f\"weighted average overlap using Jaccard similarity is:\\n\\n{w_avg_ovlp}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:07.082598Z","iopub.execute_input":"2024-10-14T12:52:07.083104Z","iopub.status.idle":"2024-10-14T12:52:07.092519Z","shell.execute_reply.started":"2024-10-14T12:52:07.083062Z","shell.execute_reply":"2024-10-14T12:52:07.091015Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"weighted average overlap using Jaccard similarity is:\n\n{0: 0.443, 1: 0.631, 2: 0.558}\n","output_type":"stream"}]},{"cell_type":"code","source":"def mbr_decode(model, text, n_samples=5, temperature=0.6, similarity_fn=jaccard_similarity):\n    samples, log_probs = generate_samples(model, text, n_samples=n_samples, temperature=temperature)\n    \n    scores = weighted_avg_overlap(samples, log_probs, similarity_fn)\n    \n    decoded_translations = [ids_to_text(sample,tokenizer_por) for sample in samples]\n    \n    max_score_key = max(scores, key=lambda k: scores[k])\n    \n    translation = decoded_translations[max_score_key]\n    \n    return translation, decoded_translations","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:07.095770Z","iopub.execute_input":"2024-10-14T12:52:07.096330Z","iopub.status.idle":"2024-10-14T12:52:07.104851Z","shell.execute_reply.started":"2024-10-14T12:52:07.096294Z","shell.execute_reply":"2024-10-14T12:52:07.103963Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"english_sentence = \"I love languages\"\n\ntranslation, candidates = mbr_decode(translator, english_sentence, n_samples=10, temperature=0.6)\n\nprint(\"Translation candidates:\")\nfor c in candidates:\n    print(c)\n\nprint(f\"\\nSelected translation: {translation}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:52:26.423302Z","iopub.execute_input":"2024-10-14T12:52:26.423660Z","iopub.status.idle":"2024-10-14T12:52:26.922069Z","shell.execute_reply.started":"2024-10-14T12:52:26.423627Z","shell.execute_reply":"2024-10-14T12:52:26.921033Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"Translation candidates:\n['eu adoro idiomas']\n['eu adoro idiomas para os idiomas eu eu amo eu odeio eu odeio eu adoro eu amo eu amo eu adoro eu amo eu beisebol eu amo eu odeio eu amo eu odeio eu adorei eu amo eu amo eu amo eu eu amo amo amo eu amo eu']\n['eu amo idiomas boa deveras meu dicas eu amo eu amo eu circo eu amo eu amo eu encontrei eu eu gramado eu amo eu amo eu adoro eu virem adoram eu amo eu naturalmente eu amo eu adoro eu amo eu eu amo eu dirija eu amo eu amo']\n['eu adoro idiomas muito palavras obrigado eu eu adoro eu amo eu amo eu vinda adoro eu amo eu amo eu amo eu amo amo eu adoro eu adorei eu adoro eu amo eu amo eu amo eu adoro eu amo eu amo eu amo eu amo eu b eu']\n['eu amo linguas falas']\n['eu amo linguas perguntar']\n['eu amo linguas segura']\n['eu amo linguas']\n['eu adoro linguas falamos']\n['eu adoro linguas']\n\nSelected translation: ['eu adoro linguas']\n","output_type":"stream"}]}]}